# 📍 키워드
- 메모리 관리
    - 메모리 관리 필요성
    - 고정 분할 방식
    - 가변 분할 방식
- 가상 메모리 개요
    - https://github.com/bombo-dev/CS-JAVA-Study/blob/main/Operating%20System/Virtual%20Memory.md
    - 가상 메모리 정의
    - 가상 메모리 필요성
    - 페이징 기법, 세그먼테이션 기법
         - https://github.com/bombo-dev/CS-JAVA-Study/blob/main/Operating%20System/Paging%20%26%20Segmentation.md
    - TLB, MMU
        - https://github.com/bombo-dev/CS-JAVA-Study/blob/main/Operating%20System/TLB%2C%20MMU.md
- 가상 메모리 관리
    - 요구 페이징
    - 페이지 교체 알고리즘
        - https://github.com/bombo-dev/CS-JAVA-Study/blob/main/Operating%20System/Page%20Replacement%20Algorithm.md
        - FIFO
        - OPT
        - LRU

<br>

# 📍 예상 질문
<details>
<summary>메모리 관리가 왜 필요한가요?</summary>
<div markdown="1">

- 프로세스 분리와 보호: 각 프로세스는 독립된 메모리 공간을 갖고, 다른 프로세스나 운영체제의 메모리 공간에 접근할 수 없도록 보호합니다. 이는 시스템의 안정성과 보안을 유지하는 데 중요합니다.
- 효율적인 메모리 사용: 멀티프로그래밍 환경에서 한정된 메모리 자원을 여러 프로세스가 공유하여 사용하기 때문에, 메모리를 효율적으로 관리하고 할당하는 것이 필수적입니다. 이를 통해 메모리 이용률과 시스템 처리량을 최대화할 수 있습니다.
- 스와핑 및 가상 메모리: 메모리가 부족할 때, 사용하지 않는 프로세스를 디스크의 스왑 영역으로 이동시키고 필요한 프로세스를 메모리로 불러오는 스와핑 기법을 사용합니다. 이는 가상 메모리 기법의 핵심으로, 더 큰 메모리를 사용하는 것처럼 효율적으로 메모리를 활용할 수 있게 합니다.

</div>
</details>
<details>
<summary>고정 분할 방식의 메모리 관리는 어떤 원리로 작동하나요?</summary>
<div markdown="1">

- 고정 분할 방식의 특징
    - 분할의 고정성: 메모리는 시스템 시작 시 미리 정해진 크기의 분할로 나뉘며, 이 분할 크기는 시스템이 실행되는 동안 변경되지 않습니다.
    - 프로세스 할당: 각 분할에는 하나의 프로세스만이 할당될 수 있으며, 프로세스의 크기가 분할의 크기보다 작을 경우 내부 단편화가 발생할 수 있습니다.
    - 단순한 관리: 고정 분할 방식은 원리가 단순하여 운영체제의 메모리 관리 오버헤드를 줄일 수 있습니다. 하지만, 이로 인해 유연성이 떨어지는 단점도 있습니다.
- 고정 분할 방식의 장단점
    - 장점: 관리가 단순하고, 시스템의 오버헤드가 적습니다. 메모리 분할이 미리 정해져 있기 때문에, 메모리 할당과 회수 과정이 간단합니다.
    - 단점: 프로세스의 크기가 분할의 크기와 정확히 일치하지 않을 경우, 메모리의 일부가 낭비되는 내부 단편화 문제가 발생할 수 있습니다. 또한, 동시에 실행할 수 있는 프로세스의 수가 분할의 수에 의해 제한됩니다.

</div>
</details>
<details>
<summary>가변 분할 방식의 메모리 관리는 어떤 원리로 작동하나요?</summary>
<div markdown="1">

- 가변 분할 방식의 특징
    - 동적 메모리 할당: 프로세스가 메모리에 적재될 때, 그 크기에 맞게 메모리 공간이 할당됩니다. 이는 메모리의 유연한 사용을 가능하게 하며, 프로세스의 크기에 따라 분할의 크기가 결정됩니다2.
    - 외부 단편화 문제: 가변 분할 방식에서는 프로세스가 메모리에서 제거될 때 남겨진 공간으로 인해 외부 단편화가 발생할 수 있습니다. 이는 메모리 공간이 충분함에도 불구하고 연속적인 공간이 아니기 때문에 새로운 프로세스를 할당할 수 없는 상황을 만듭니다.
- 가변 분할 방식의 메모리 관리 방법
    - 최초 적합(First-fit): 가용 공간을 처음부터 탐색하여 프로세스 크기보다 크거나 같은 첫 번째 공간에 프로세스를 할당합니다.
    - 최적 적합(Best-fit): 모든 가용 공간을 탐색하여 프로세스 크기와 가장 잘 맞는 가장 작은 공간에 할당합니다.
    - 최악 적합(Worst-fit): 가장 큰 가용 공간에 프로세스를 할당하여, 큰 공간을 활용하려는 전략입니다.

</div>
</details>
<details>
<summary>가변 분할 방식의 메모리 관리와 고정 분할 방식의 차이점은 무엇인가요?</summary>
<div markdown="1">

- 고정 분할 방식
    - 정의: 메모리를 미리 정해진 크기의 여러 영역으로 나누고, 각 영역에 하나의 프로세스를 할당하는 방식입니다.
    - 장점: 구현이 간단하고, 메모리 관리가 용이합니다.
    - 단점: 메모리의 크기가 고정되어 있어, 프로세스의 크기가 영역의 크기보다 작을 경우 남는 공간이 발생하며, 이는 내부 단편화를 초래합니다. 또한, 큰 프로세스를 수용할 수 없는 경우가 발생할 수 있습니다.
- 가변 분할 방식
    - 정의: 프로세스의 크기에 따라 메모리를 동적으로 할당하는 방식입니다. 프로세스가 메모리에 적재될 때 필요한 만큼의 메모리를 할당받습니다.
    - 장점: 메모리를 효율적으로 사용할 수 있으며, 크기가 다양한 프로세스를 수용할 수 있습니다.
    - 단점: 메모리 할당과 해제가 반복될 때 메모리에 작은 빈 공간들이 생기는 외부 단편화 문제가 발생할 수 있습니다. 또한, 메모리 관리가 복잡해집니다.

</div>
</details>
<details>
<summary>가상 메모리란 무엇인가요?</summary>
<div markdown="1">

- 가상 메모리는 컴퓨터 시스템에서 실제 메모리보다 더 큰 메모리 영역을 프로그램에 제공하는 기술입니다. 이를 통해, 프로그램은 물리적 메모리의 한계를 넘어서는 데이터와 코드를 처리할 수 있게 됩니다. 가상 메모리 시스템은 실제 메모리의 크기와 상관없이 사용자나 응용 프로그램에게 마치 무한한 메모리 공간이 있는 것처럼 느끼게 합니다.
- 가상 메모리의 핵심 원리
    - 메모리 추상화: 가상 메모리는 물리적 메모리의 크기를 초월하여, 사용자에게 더 큰 메모리 공간을 제공하는 추상화된 메모리 모델을 만듭니다.
    - 부분 적재: 프로세스 실행 시 필요한 부분만 메모리에 적재하여, 전체 프로세스가 메모리에 올라가지 않아도 실행될 수 있도록 합니다4.
- 가상 메모리의 장점
    - 메모리 활용도 향상: 실제 메모리보다 큰 프로세스 실행이 가능해지며, 여러 프로세스를 동시에 실행할 수 있습니다.
    - 프로그램 크기 제한 완화: 프로그램이 물리적 메모리 크기에 구애받지 않고, 필요한 부분만 메모리에 적재하여 실행할 수 있습니다.
    - 데이터 보호 및 공유 용이: 가상 메모리는 프로세스 간 메모리 공간을 분리하여 데이터 보호를 강화하고, 필요한 경우 메모리 공간을 공유하기 쉽게 합니다.

</div>
</details>
<details>
<summary>가상 메모리가 도입된 이유는 무엇인가요?</summary>
<div markdown="1">

- 가상 메모리는 컴퓨터 시스템의 메모리 관리 기법 중 하나로, 물리적 메모리의 한계를 극복하고 효율적으로 메모리를 사용하기 위해 도입되었습니다. 멀티태스킹 환경에서 여러 프로그램이 동시에 실행될 때, 각 프로그램이 독립적으로 메모리를 사용하는 것처럼 관리할 필요성이 커졌기 때문입니다. 

</div>
</details>
<details>
<summary>가상 메모리는 어떤 원리로 작동하나요?</summary>
<div markdown="1">

- 가상 메모리의 기본 원리
    - 논리 주소와 물리 주소의 분리: 가상 메모리 시스템에서는 프로그램이 사용하는 주소(논리 주소)와 실제 메모리 상의 주소(물리 주소)를 분리합니다. 이를 통해 프로그램은 물리 메모리의 실제 구조와 무관하게 자신만의 주소 공간을 가질 수 있습니다4.
    - 페이지 교체 알고리즘: 가상 메모리는 '페이지'라는 고정 크기의 블록으로 메모리를 관리합니다. 프로그램 실행 시 필요한 페이지만 물리 메모리로 적재되며, 물리 메모리가 가득 차면 일부 페이지를 디스크로 옮기는 페이지 교체가 일어납니다. 이 과정에서 다양한 페이지 교체 알고리즘이 사용됩니다.
- 가상 메모리의 작동 과정
    - 요구 페이징(Demand Paging): 프로그램 실행 중 필요한 데이터가 물리 메모리에 없을 경우, '페이지 폴트(page fault)'가 발생합니다. 이때 운영체제는 해당 데이터가 저장된 디스크의 위치를 찾아 물리 메모리로 적재합니다.
    - 주소 변환: 프로그램이 사용하는 논리 주소는 실행 시 물리 주소로 변환되어야 합니다. 이 변환 과정은 페이지 테이블을 통해 이루어지며, CPU 내의 메모리 관리 장치(MMU)가 이를 담당합니다.
    - 스왑 아웃(Swap Out): 물리 메모리가 부족할 때, 운영체제는 사용 빈도가 낮은 페이지를 디스크로 이동시킵니다. 이 과정을 스왑 아웃이라고 하며, 필요한 메모리 공간을 확보합니다.

</div>
</details>
<details>
<summary>TLB는 무엇이고, MMU는 무엇인가요?</summary>
<div markdown="1">

- TLB(Translation Lookaside Buffer)
    - 정의: TLB는 가상 메모리 주소를 물리 메모리 주소로 변환할 때 사용되는 캐시의 일종입니다. 가장 최근에 사용된 페이지 테이블의 매핑 정보를 저장하여, 주소 변환 과정을 빠르게 만듭니다. 
    - 역할: CPU가 메모리에 접근할 때, 가상 주소를 물리 주소로 변환해야 합니다. TLB는 이 변환 과정에서 페이지 테이블을 직접 참조하는 대신, 빠르게 주소 변환을 도와주는 역할을 합니다. 
- MMU(Memory Management Unit)
    - 정의: MMU는 CPU가 메모리에 접근하는 것을 관리하는 컴퓨터 하드웨어 부품입니다. 가상 메모리 주소를 물리 메모리 주소로 변환하고, 메모리 보호, 캐시 관리, 버스 중재 등의 역할을 담당합니다. 
    - 기능: MMU는 가상 주소 공간을 물리 주소 공간으로 매핑하며, 이 과정에서 TLB를 사용하여 주소 변환 속도를 향상시킵니다. 또한, 프로세스마다 독립된 주소 공간을 제공하여 시스템의 안정성과 보안을 강화합니다. 

</div>
</details>
<details>
<summary>내부 단편화와 외부 단편화에 대해 설명해 주세요.</summary>
<div markdown="1">

- 내부 단편화: 프로세스에 할당된 메모리 영역이 실제로 사용하는 것보다 클 때, 사용되지 않는 부분이 생기는 현상입니다. 즉, 메모리가 낭비되는 상황을 말합니다.
- 외부 단편화: 메모리에 충분한 총 공간이 있음에도 불구하고, 연속적인 공간이 아니어서 특정 프로세스나 데이터를 할당할 수 없는 상황입니다.

</div>
</details>
<details>
<summary>페이징 기법이란 무엇인가요?</summary>
<div markdown="1">

- 페이징 기법은 프로세스의 메모리 공간을 동일한 크기의 '페이지' 단위로 나누어, 물리적 메모리의 서로 다른 위치에 저장하는 메모리 관리 방식입니다. 이 방법은 프로세스가 사용하는 메모리 공간을 더욱 효율적으로 관리할 수 있게 해줍니다. 
- 페이징 기법의 핵심 원리
    - 논리적 주소와 물리적 주소의 분리: 페이징 기법에서는 프로세스가 사용하는 논리적 주소 공간과 실제 메모리에 할당되는 물리적 주소 공간을 분리하여 관리합니다. 이를 통해 메모리 관리의 유연성을 높일 수 있습니다.
    - 페이지와 프레임: 메모리는 '페이지'라는 고정된 크기의 단위로 나누어지며, 물리적 메모리는 '프레임'이라는 동일한 크기의 단위로 구성됩니다. 각 페이지는 물리적 메모리의 프레임에 매핑되어 저장됩니다.
- 페이징 기법의 장점과 단점
    - 장점: 외부 단편화 문제를 해결할 수 있으며, 메모리를 더욱 효율적으로 사용할 수 있습니다. 또한, 프로세스 간 메모리 보호 기능을 강화할 수 있습니다.
    - 단점: 내부 단편화 문제가 발생할 수 있으며, 페이지 테이블 관리에 추가적인 메모리가 필요할 수 있습니다.
- 페이징 기법의 작동 과정
    1. 주소 변환: 프로세스가 메모리에 접근할 때, 논리적 주소는 페이지 테이블을 통해 물리적 주소로 변환됩니다. 이 과정에서 CPU 내의 메모리 관리 장치(MMU)가 중요한 역할을 합니다.
    2. 페이지 폴트 처리: 요청된 페이지가 물리적 메모리에 없을 경우, 페이지 폴트가 발생하고, 운영체제는 해당 페이지를 디스크에서 찾아 물리적 메모리로 적재합니다.

</div>
</details>
<details>
<summary>세그먼테이션 기법이란 무엇인가요?</summary>
<div markdown="1">

- 세그먼테이션 기법은 프로세스의 메모리를 다양한 크기의 논리적 단위인 '세그먼트'로 나누어 관리하는 메모리 관리 전략입니다. 이 방식은 프로그램의 논리적 구조를 반영하여 메모리를 할당하므로, 페이징 기법과 비교했을 때 더욱 직관적인 메모리 관리가 가능합니다.
- 세그먼테이션 기법의 핵심 원리
    - 가변적 세그먼트 크기: 세그먼테이션은 프로세스를 구성하는 논리적 단위인 세그먼트로 나누며, 각 세그먼트의 크기는 서로 다를 수 있습니다. 이는 프로그램의 논리적 구조에 따라 메모리를 효율적으로 할당할 수 있게 해줍니다.
    - 논리적 구조와의 일치: 세그먼테이션은 프로그램의 논리적 구조를 메모리에 그대로 반영할 수 있어, 프로그래머가 프로그램을 더욱 직관적으로 이해하고 관리할 수 있게 합니다.
- 세그먼테이션 기법의 장점과 단점
    - 장점: 프로그램의 논리적 구조를 메모리에 직접 반영할 수 있으며, 메모리 보호와 공유가 용이합니다.
    - 단점: 외부 단편화 문제가 발생할 수 있으며, 세그먼트 테이블 관리에 추가적인 메모리가 필요할 수 있습니다.
- 세그먼테이션 기법의 작동 과정
    1. 주소 변환: 프로세스가 메모리에 접근할 때, 세그먼트 번호와 변위(offset)를 사용하여 물리적 주소로 변환됩니다. 이 과정에서 세그먼트 테이블이 중요한 역할을 합니다.
    2. 메모리 보호 및 공유: 각 세그먼트는 접근 권한을 가지고 있어, 메모리 보호가 가능합니다. 또한, 필요한 경우 여러 프로세스가 동일한 세그먼트를 공유할 수 있습니다.

</div>
</details>
<details>
<summary>세그먼테이션 기법의 특징과 페이징 기법과의 차이점은 무엇인가요?</summary>
<div markdown="1">

- 세그먼테이션 기법의 특징
    - 가변 크기의 세그먼트: 세그먼테이션은 프로세스를 서로 다른 크기의 논리적 단위인 세그먼트로 나눕니다. 이는 프로그램의 논리적 구조를 반영하여 메모리를 할당하는 데 유리합니다.
    - 세그먼트 테이블 사용: 각 세그먼트의 시작 주소와 길이 정보를 저장하는 세그먼트 테이블을 사용하여 주소 변환을 수행합니다.
    - 외부 단편화 문제: 세그먼트의 크기가 가변적이기 때문에 메모리에 할당되지 않은 작은 공간들이 발생할 수 있습니다. 이를 외부 단편화라고 합니다.
- 페이징 기법의 특징
    - 고정 크기의 페이지: 페이징 기법에서는 메모리를 고정된 크기의 페이지로 나누고, 프로세스 또한 페이지 단위로 나누어 메모리에 할당합니다.
    - 페이지 테이블 사용: 각 페이지의 물리적 주소 정보를 저장하는 페이지 테이블을 사용하여 주소 변환을 수행합니다.
    - 내부 단편화 문제: 페이지의 크기가 고정되어 있기 때문에, 페이지의 마지막 부분이 사용되지 않는 경우가 발생할 수 있습니다. 이를 내부 단편화라고 합니다.
- 세그먼테이션과 페이징의 주요 차이점
    - 메모리 할당 단위: 세그먼테이션은 가변 크기의 세그먼트를 사용하는 반면, 페이징은 고정 크기의 페이지를 사용합니다.
    - 단편화 문제: 세그먼테이션은 외부 단편화 문제가 발생할 수 있으나, 페이징은 내부 단편화 문제가 발생할 수 있습니다.
    - 주소 변환 메커니즘: 세그먼테이션은 세그먼트 테이블을, 페이징은 페이지 테이블을 사용하여 주소 변환을 수행합니다.

</div>
</details>
<details>
<summary>요구 페이징이란 무엇이며, 왜 필요한가요?</summary>
<div markdown="1">

- 필요한 페이지만 메모리에 올림: 프로세스는 페이지의 조합으로 구성되며, 요구 페이징은 실행에 필요한 페이지만을 메모리에 올리는 방식입니다. 이를 통해 메모리 사용을 최적화할 수 있습니다. 
- 요구 페이징의 필요성
    - 메모리 효율성 증가: 전체 프로세스를 메모리에 올리지 않고, 필요한 부분만을 올림으로써 메모리 사용을 효율적으로 관리할 수 있습니다.
    - 응답 시간 단축: 필요한 페이지만을 메모리에 올리기 때문에, 프로세스 시작 시간이 단축되고, 사용자에게 빠른 응답을 제공할 수 있습니다.
    - 가상 메모리 사용: 요구 페이징은 가상 메모리 시스템의 핵심 기법 중 하나로, 물리 메모리의 크기를 초과하는 프로그램도 실행할 수 있게 합니다.
- 요구 페이징의 구현
    - 하드웨어의 지원 필요: 요구 페이징을 구현하기 위해서는 하드웨어의 지원이 필수적입니다. 예를 들어, 유효 비트(valid bit)가 추가된 페이지 테이블을 통해 메모리에 존재하는 페이지와 그렇지 않은 페이지를 구분합니다. 

</div>
</details>
<details>
<summary>페이지 부재에 대해서 설명해주세요.</summary>
<div markdown="1">

- 정의: 프로세스가 요청한 페이지가 메인 메모리에 없어, 해당 페이지를 디스크에서 메인 메모리로 가져와야 하는 상황입니다.
- 발생 과정: CPU가 페이지를 참조하려 할 때, 페이지 테이블에서 해당 페이지가 메모리에 없다는 것을 알게 되면, 페이지 부재(trap)가 발생하고 운영체제가 이를 처리합니다.
    1. CPU가 가상 주소를 MMU에게 요청합니다.
    2. MMU는 먼저 TLB로 가서 그 가상주소에 대한 물리주소가 캐싱돼 있는지 확인합니다.
    3. TLB에 캐싱된 물리주소가
    3-1. 있으면 MMU가 해당 페이지의 물리 주소로 데이터를 갖고 와서 CPU에게 보냅니다.
    3-2. 없으면 MMU가 CR3 레지스터를 가지고 물리 메모리에 해당 프로세스의 페이지 테이블에 접근합니다.
    4. MMU가 페이지 테이블에서 물리주소가 있는지 valid bit를 확인합니다.
    5. valid bit의 값이
    5-1. 1이면 MMU가 해당 페이지의 물리 주소로 데이터를 갖고 와서 CPU에게 보냅니다.
    5-2. 0이면 MMU가 페이지 폴트 인터럽트를 운영체제에 발생시킵니다.
    6. 운영체제는 해당 페이지를 저장공간에서 가져옵니다.
    7. 운영체제는 저장공간에서 가져온 데이터를 메모리에 올려주고, 페이지 테이블을 업데이트 해줍니다. valid bit -> 1, 물리주소를 업데이트합니다.
    8. 운영체제는 CPU에게 프로세스를 다시 실행하라고 합니다. (PCB 저장 정보 기반으로)
    9. CPU는 다시 MMU에 가상 주소를 요청합니다.

</div>
</details>
<details>
<summary>페이지 부재가 발생하는 이유는 무엇인가요?</summary>
<div markdown="1">

- 물리 메모리 부족: 시스템의 물리 메모리에 비어 있는 프레임이 없거나, 미리 정한 수보다 적을 때 발생합니다. 
- CPU의 무효 페이지 접근: CPU가 메모리 관리 단위(MMU)에 의해 관리되는 주소 공간 내에서 유효하지 않은 페이지에 접근하려고 할 때 발생합니다. 
- 요구 페이징(Demand Paging): 프로그램 실행 중 요구되는 페이지가 계속 증가하여, 결국 메모리가 가득 차게 되면 새로운 페이지 요청에 의해 페이지 부재가 발생합니다. 
- Major Page Fault: 요청한 페이지가 물리 메모리로부터 page-out 되어 보조 기억장치의 가상 메모리에 저장되어 있을 때, 해당 페이지를 다시 물리 메모리로 page-in 해야 하는 상황입니다. 이 과정에서 디스크 I/O가 발생합니다. 4
- Minor Page Fault: 요청한 페이지가 물리 메모리에는 로드되었지만, MMU에는 로드되어 있지 않다고 표시된 경우입니다. 
- Invalid Page Fault: 요청한 페이지가 스왑 영역의 밖을 참조하거나, 페이지를 쓰기 불가능한 영역에 쓰려고 할 때 발생합니다. 이 경우, 시스템은 세그멘테이션 폴트(Segmentation Fault)를 발생시킬 수 있습니다. 

</div>
</details>
<details>
<summary>FIFO, OPT, LRU 페이지 교체 알고리즘의 각각의 특징과 차이점은 무엇인가요?</summary>
<div markdown="1">

- FIFO(First In, First Out) 페이지 교체 알고리즘
    - 특징: 가장 오래 전에 메모리에 올라온 페이지를 교체 대상으로 선택합니다. 구현이 간단하고 이해하기 쉽습니다.
    - 단점: 최근에 자주 사용되는 페이지라도 메모리에 오래 머물러 있다면 교체 대상이 될 수 있어, 효율성이 떨어질 수 있습니다.
- OPT(Optimal Page Replacement) 알고리즘
    - 특징: 미래에 가장 오랫동안 사용되지 않을 페이지를 교체 대상으로 선택합니다. 이론적으로 최적의 페이지 교체 알고리즘입니다.
    - 단점: 미래의 페이지 사용 패턴을 예측해야 하기 때문에 실제 시스템에서 구현하기 어렵습니다.
- LRU(Least Recently Used) 페이지 교체 알고리즘
    - 특징: 가장 오랫동안 사용되지 않은 페이지를 교체 대상으로 선택합니다. 최근 사용 패턴을 기반으로 하여 효율적인 페이지 교체를 가능하게 합니다.
    - 단점: 페이지의 사용 기록을 관리해야 하므로 구현이 복잡하고, 관리에 추가적인 비용이 발생할 수 있습니다.

</div>
</details>

<br>

# 📍 Reference
