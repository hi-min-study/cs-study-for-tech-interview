## 내용 정리
### 커널

운영체제는 `커널`과 `시스템 프로그램`으로 구분될 수 있다. `커널`은 **운영체제의 핵심으로 컴퓨터 자원들을 관리하는 역할**을 한다. 하지만 `커널`은 **사용자와의 상호작용은 전혀 지원하지 않는다.** 그래서 사용자와 직접적인 상호작용을 위해서 시스템 프로그램이 필요하다. 시스템 프로그램의 예로 쉘(Shell)이라는 명령어 해석기가 있다. `쉘`은 **사용자가 컴퓨터에게 전달하는 명령을 해석하는 프로그램으로 사용자와와의 상호작용을 가능하게 한다.**

정리를 하면 **`'운영체제'`**는 **커널과 함께 사용자 편의를 위한 시스템 프로그램**을 포함하며, **`'커널'`**은 **컴퓨터 자원을 관리하는 운영체제의 핵심 부분**이다.

**커널**은 **컴퓨터의 물리적(하드웨어) 자원과 추상화 자원을 관리**하기 위해 **시스템의 다른 모든 부분을 위한 기본적인 서비스를 제공**하고, **하드웨어를 관리**하며, **시스템 자원을 나눠준다.** 추상화는 물리적으로 하나 뿐인 하드웨어를 여러 사용자들이 번갈아 사용하게 중재함으로서 한 개의 하드웨어가 여러개인 것처럼 보여지게 한다. 이를 위해 **커널은 하나의 하드웨어 자원을 여러 사용자들을 위한 복수 개의 추상화된 객체로 관리**한다.

### 커널이 하는 일

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/f161c15f-c5f0-4683-9793-c7551a62792f/9462a0f1-7f1d-4bf6-a460-b6652083bdca/Untitled.png)

- **태스크(task)관리자**: CPU를 task라는 추상적인 자원으로써 제공
- **메모리 관리자**: 메모리를 segment나 page로 제공
- **파일시스템**: 디스크를 파일로 제공
- **네트워크 관리자**: 네트워크 장치를 소켓으로 제공
- **디바이스 드라이버 관리자**: 각종 장치를 디바이스 드라이버를 통해 일관되게 접근하도록 함

커널의 구성요소, 즉 관리자들이 존재하는 공간이 Kernel Space이다. Kernel Space 위에 사용자로 여겨지는 태스크(process)들이 존재하는 User Space가 있다. (프로그램 파일이 결국 task가 된다.)

Kernel Space와 User Space 사이에 System Call Interface가 있다. User Space의 task들이 커널이 관리하는 자원에 접근해야 할 필요가 있으면 System Call Interface를 통해 Kernel Space의 자원 관리자에게 요청이 전달된다. 그리고 이 커널의 각 자원 관리자는 사용자 요청에 맞게 알맞는 하드웨어에 사용자 명령을 전달하고 작업을 수행한다.

정리하자면, **'커널'은 사용자가 system call을 통해 컴퓨터 자원을 사용할 수 있게 해주는 자원관리자라고 볼 수 있다.**

### 유저 영역(User land)과 커널 영역(Kernel land)의 차이점

운영체제는 컴퓨터의 메모리를 관리한다. 컴퓨터를 안전하게 관리하기 위해서 유저 영역과 커널 영역으로 나누어 관리를 한다.

- **유저 영역(user land)**: 프로그램이 동작하기 위해 사용되는 메모리 공간(stack, heap, bss, data, text 영역)
- **커널 영역(kernel land)**: 운영체제를 실행시키기 위해 필요한 메모리 공간

명령어 수행 과정에서 CPU는 항상 메모리에 이번에 수행해야 할 instruction의 주소를 건네준 후 instruction과 관련된 데이터나 코드를 받아서 실행한다. 이 과정에서 지금 현재 상태가 유저 모드인지 커널 모드인지가 중요하다.

커널 모드의 경우, CPU는 어떠한 영역의 메모리라도 접근하고 모든 instruction을 실행시킬 수 있다. 한 마디로 모든 영역의 접근이 허용된다는 의미다. 하지만 유저 모드의 경우는 오직 자신의 메모리 영역에만 접근할 수 있다.

### 이러한 모드를 왜 나눈 것일까?

커널에서 중요한 자원, 즉 **운영체제를 실행시키기 위한 자원을 관리하기 때문에 일반 사용자가 그 중요한 자원에 접근하지 못하도록 하기 위함이다.**

### 시스템콜

## 시스템 콜, System Call

시스템 호출(system call)은 운영 체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다.

사용자 프로그램이 디스크 파일을 접근하거나 화면에 결과를 출력하는 등의 작업이 필요한 경우, 즉 사용자 프로그램이 특권 명령의 수행을 필요로 하는 경우, 운영체제에게 특권 명령의 대행을 요청하는 것이 시스템 콜이다.

- 통상적으로 시스템 콜은 여러 종류의 기능으로 나누어진다.
- 각 시스템 콜에는 번호가 할당되고 시스템 콜 인터페이스는 **시스템 콜 번호와 시스템 콜 핸들러 함수 주소로 구성되는 시스템 콜 테이블**을 유지한다.
- 운영체제는 자신의 커널 영역에서 해당 인덱스가 가리키는 주소에 저장되어 있는 루틴을 수행한다.
- 작업이 완료되면 CPU에게 인터럽트를 발생시켜 수행이 완료 되었음을 알린다.

## 시스템 콜이 필요한 이유

!https://velog.velcdn.com/images/nnnyeong/post/5ffac049-22e2-486e-8d4d-11f7f0d31778/image.png

우리가 일반적으로 사용하는 프로그램은 '응용 프로그램' 이다. 유저레벨의 프로그램은 유저레벨의 함수들 만으로는 많은 기능을 구현하기 힘들기 때문에, **커널(kernel)** 의 도움을 반드시 받아야 한다. 이러한 작업은 응용프로그램으로 대표되는 유저 프로세스(User Process)에서 유저모드에서는 수행할 수 없다. **반드시 kernel에 관련된 것은 커널모드로 전환한 후에야**, 해당 작업을 수행할 권한이 생긴다.

> 그렇다면 권한은 왜 필요한 것일까?
>
>
> 그 이유는 만약 권한이 없을 때, 해커가 피해를 입히기 위해 악의적으로 시스템 콜을 사용하는 경우나 초보 사용자가 하드웨어 명령어를 잘 몰라서 아무렇게 함수를 호출했을 경우에 시스템 전체를 망가뜨릴 수도 있기 때문이다. 따라서 이러한 명령어들은 특별하게 **커널 모드**에서만 실행할 수 있도록 설계되었고, 만약 유저 모드에서 시스템 콜을 호출할 경우에는 운영체제에서 불법적인 접근이라 여기고 trap을 발생시킨다.
>

## 시스템 콜의 유형

### 프로세스 컨트롤

- 프로세스 생성 및 종료
- 메모리에 로드, 실행
- 프로세스 속성 값 확인, 지정
- wait 이벤트, signal 이벤트
- 메모리 할당
- 예) fork, wait, exec 등

### 파일 매니지먼트

- 파일 생성, 파일 삭제
- 열기, 닫기
- 읽기, 쓰기, Reposition
- 파일 속성 값 확인, 지정
- 예) open, read, write, close 등

### 디바이스 매니지먼트

- 디바이스 요청 및 해제
- 읽기, 쓰기, Reposition
- 디바이스 속성 확인, 지정
- 비 물리적인 디바이스 해제 및 장착

### 정보 관리

- 시간 확인, 시간 지정
- 시스템 데이터 확인, 지정
- 프로세스, 파일, 디바이스 속성 가져오기
- 프로세스, 파일, 디바이스 속성 설정하기

### 통신

- 커뮤니케이션 연결 생성 및 삭제
- 메시지 송신, 수신
- 상태 정보 전달
- remote 디바이스 해제 및 장착

### 보안

- 파일 권한 변경 (chmod)
- 파일 소유자 변경 (chown)

## 유저 모드와 커널 모드

### 유저 모드

PC register 가 사용자 프로그램이 올라가 있는 메모리 위치를 가리키고 있을 때 현재 사용자 프로그램을 수행중이라고 하며 CPU 가 유저모드에서 수행중이라고 말한다.

### 커널 모드

PC register 가 운영체제가 존재하는 부분을 가리키고 있다면 현재 운영체제의 코드를 수행중이라고 하며 CPU가 커널모드에서 수행중이라고 말한다.

### 프로세스

## 개념

현재 수행중인 프로그램을 의미하는 개념으로, 프로그램이 수행되기 위한 여러 정보들로 구성되어 있다.

가장 먼저 프로세스는 실행될 프로그램의 코드와 프로그램에 필요한 데이터를 가지고 있어야 한다. 또한 프로세서가 프로그램을 수행하기 위해서는 식별자와 상태 등 여러 문맥정보가 필요한데, 프로세스는 이 정보들을 프로세스 제어블록(Process Control Block, PCB)라는 자료구조에 담아 관리한다.

PCB에는 다음과 같은 정보들이 저장된다

- 식별자
- 프로세스의 상태
- PC(Program Counter)
- 메모리 포인터 : 프로그램 코드, 데이터등의 메모리상의 주소
- Context data
- I/O state : 프로세스에 할당된 I/O장치, 및 이벤트 정보
- Accounting information : 리소스 사용률 등의 모니터링 정보

### 프로세스 구성 요소

- 프로그램 코드 및 데이터
- PCB
1. **코드(Code) 영역**
    - 프로그램 코드 자체
    - 주기억장치에 CPU가 해석할 수 있는 Binary Code 상태로 올라가게 되는데 이 영역을 뜻한다.
2. **데이터(Data) 영역**
    - 프로그램의 전역 변수(Global Variable)나 정적 변수(Static Variable)의 할당
3. **스택(Stack) 영역**
    - 지역 변수(Local Variable) 할당과 함수 호출 시 전달되는 인수(Argument) 값
4. **힙(Heap) 영역**
    - 동적 할당

### 프로세스의 한계

과거에는 프로그램을 실행할 때 프로세스 하나만을 사용해서 이용했었다. 하지만 기술이 발전됨에 따라 프로그램이 복잡해지고 다채로워짐으로써 프로세스 작업 하나만을 사용해서 프로그램을 실행하기에는 한계가 있었다.

오늘날 컴퓨터는 파일을 다운 받으며 다른 일을 하는 멀티 작업은 너무 당연한 기능이라고 생각할지 모르겠지만, 과거에는 파일을 다운받으면 실행 시작부터 실행 끝까지 프로세스 하나만을 사용하기 때문에 다운이 완료될때까지 하루종일 기다려야 했다.

그렇다고 동일한 프로그램을 여러 개의 프로세스로 만들게 되면, 그만큼 메모리를 차지하고 CPU에서 할당받는 자원이 중복되게 될 것이다. 스레드(Thread)는 이러한 프로세스 특성의 한계를 해결하기 위해 탄생 하였다.

### 프로세스 상태

### 프로세스 생성, 종료

프로세스의 상태를 정의하기 전에 모든 프로세스의 라이프사이클은 생성(creation)으로 시작되어 종료(termination)로 끝난다.

- 프로세스 생성 : 새로운 프로세스가 생성되기 위해서 운영체제는 프로세스 자료구조를 만들고 메모리공간을 할당한다. 이 과정을 통해 생성된 프로세스는 New상태를 가진다. 프로세스가 생성되는 이벤트는 다음과 같다.
    - 새로운 배치 작업 제출
    - 사용자가 터미널에 로그온
    - 운영체제의 서비스제공 : 사용자 프포그램에서 I/O작업을 요청하는등의 경우 운영체제가 관련된 서비스의 프로세스를 생성한다.
    - 프로세스 스폰(Process Spawn) : 하나의 프로세스가 다른 프로세스를 생성하도록 운영체제에게 요청하는 경우. 이때, 스폰을 요청한 프로세스는 부모 프로세스, 스폰당한 프로세스는 자식 프로세스라 한다.
- 프로세스 종료 : 프로세스가 아래의 이유들로 중단(abort)되거나 중지(halt)되면 해당 프로세스는 수행가능 프로세스 풀에서 방출되고 프로세스의 정보는 유틸리티 프로그램에 의해 기록된 후 삭제된다. 이 단계의 프로세스는 Exit상태를 가진다.
    - 정상 완료
    - 오류 및 결함
    - 부모 프로세스의 요청 혹은 부모 프로세스 종료

### Dispatcher

Dispatcher는 OS 프로그램의 일부로, 실행중인 프로그램을 중단하고 다른 프로그램을 실행시키도록 하는 프로그램이다.

Interrupt(timeout, I/O request)가 발생하거나 종료된 프로세스로부터 준비 중인 프로세스를 수행 상태로 만들 때 항상 Dispatcher가 수행된다.

## 📙 Two-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F38db7a4a-ce51-483c-a20d-badf006ecf45%2Fimage.png

가장 간단한 모델이다.

two-state 모델에는 Not Running과 Running 상태 두 가지로 나뉜다.

- Not Running : 실행 대기 중인 상태
- Running : 현재 실행 중인 상태

### State Transitions

새 프로세스가 생성되면 OS는 프로세스의 PCB(Program Control Block)를 생성하고 not running 상태로 초기화 시킨다.

not running 상태인 프로세스들은 Queue에서 대기하게 되는데, Queue에는 각 프로세스의 PCB 주소를 가르키는 포인터를 갖고 있다.

만약 현재 실행중인 running 상태의 프로세스에서 Interrupt가 발생하면 OS는 해당 프로세스를 not running 상태로 옮긴다.

그러면 dispatcher가 Queue에서 대기 중인 프로세스들 중 하나를 골라 running 상태로 옮긴다.

## 📕 Five-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F861fd89e-17a6-433e-88fe-832a606e96d8%2Fimage.png

five-state 모델은 다섯가지 상태로 나뉜다.

- New : 프로세스가 만들어진 상태이다. 프로세스가 생성되면 바로 Ready 단계로 가면 되는거 아닌가? 라고 생각할 수 있다. 하지만 프로세스가 만들어지면 메모리도 할당해야하고 프로세스의 정보를 담고 있는 PCB와 프로세스가 실행되면서 사용할 스택 메모리도 할당하고 초기화해줘야 한다. 그렇기 때문에 프로세스 생성에는 시간이 걸리고 New 상태에 어느 정도 머물러야 한다.
- Ready : 실행을 하기 위해 기다리는 상태이다. 언제든지 실행할 준비가 되어있고, CPU를 할당해주면 바로 실행할 수 있는 단계이다.
- Running : 프로세스가 CPU를 차지하고 실행하고 있는 상태이다.
- Blocked : CPU를 할당해주어도 실행할 수 없는 상태이다.(I/O request, 다른 프로세스가 끝날 때까지 대기 등등)
- Exit : 프로세스가 끝나게 되면 프로세스가 할당 받았던 자원들을 반납해야한다. 따라서 Exit 상태에서도 처리 시간이 걸린다.

### State Transitions

**New → Ready**

New 상태에서 Ready 상태로 자연스럽게 넘어가는 것이 아니라 OS가 Ready 단계로 허락(Admit)할 때 넘어갈 수 있다.

OS의 허락을 맡는 이유는 메모리 자원 문제와 CPU 문제가 있다.

메모리의 공간은 한정적이기 때문에 메모리에 올릴 수 있는 프로그램도 한정적이다. 그렇기 때문에 프로그램을 메모리에 올리기 전에 올려도 되는지 OS의 허락이 필요하다.

두 번째 이유로 CPU가 있다. CPU는 프로그램을 Time Sharing을 통해 동시에 진행하는 것처럼 보이게 한다. 하지만 프로그램이 많아지면 각 프로그램의 대기 시간이 길어지게 되고 이는 버벅이는 것처럼 보이는 문제가 될 수 있다.

**Ready → Running**

Dispatcher가 대기하고 있는 프로그램 중 적절한 프로그램을 골라 Running 상태로 옮긴다.

**Running → Exit**

OS는 프로그램이 종료하게 되면 Exit 상태로 옮긴다.

**Running → Ready**

CPU는 Time Sharing을 통해 프로세스들을 실행시키므로 프로그램이 길면 timeout이 걸려 Ready 상태로 돌아가게 된다.

**Running → Blocked**

프로그램 실행 중 I/O request가 발생하거나 OS에 어떤 작업을 요청하면 Blocked 상태로 변경한다.

**Blocked → Ready**

기다리던 이벤트가 발생하면 바로 Running 상태로 가는 것이 아닌 Ready 상태로 간다.

## 📗 Seven-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F214b2594-8ed1-47f2-8ee6-40ff4c963473%2Fimage.png

Five state process model with two suspended states

> Suspend란?
>
>
> Suspend는 메모리에서 꺼내서 하드디스크로 옮기는 것이다.
>
> Queue에 있는 프로그램의 포인터를 이용하여 옮긴다.
>

five-state 모델에서 Ready/Suspend 상태와 Blocked/Suspend 상태가 추가된 모델이다.

- Ready/Suspend : I/O 작업이나 요청한 작업이 끝났지만 메모리에 자리가 없어 여전히 하드디스크에 있는 상태이다.
- Blocked/Suspend : 요청한 작업이 끝나지 않았고, 메모리에 있던 프로세스들이 Swaping으로 인해 하드디스크로 내려간 상태이다.

> Swaping이란?
>
>
> 메모리의 크기는 한정적이기 때문에 들어올 수 있는 프로그램의 수는 정해져 있다.
>
> 올라온 프로세스들이 모두 block이 되면 CPU가 하는 일이 없어지기 때문에 하드디스크에서 대기 중인 프로세스들을 메모리에 올리고 기존의 메모리에 있던 프로세스들은 하드디스크로 내린다.
>
> 이 작업을 Swaping이라고 한다.
>

### State Transitions

**Blocked → Blocked/Suspend**

메모리에 올라와 있는 프로세스들이 모두 요청한 작업을 하느라 block 상태이고, 하드디스크에 Swapped 되었던 프로세스들을 메모리에 올려야 한다. 그러기 위해 메모리에 있던 프로세스들을 하드디스크의 Swapped Area로 옮긴다.

**Blocked/Suspend → Blocked**

요청한 작업이 다 끝나지 않았지만 메모리에 공간이 충분히 있을 경우 다시 메모리로 올라갈 수 있다.

**Blocked/Suspend → Ready/Suspend**

요청한 작업이 다 끝났지만 메모리에 공간이 없는 경우 Ready/Suspend 상태로 옮긴다.

**Ready/Suspend → Ready**

Ready/Suspend 상태에서 대기하던 중 메모리에 공간이 생겨 다시 Ready 상태로 변경한다.

**Ready → Ready/Suspend**

여러 suspend 이유로 Ready에서 Ready/Suspend로 옮겨질 수 있다. 예를 들어 프로세스의 우선순위 때문에 메모리에 공간을 만들어야할 경우 Ready/Suspend 상태로 옮겨진다.

**New → Ready/Suspend**

만약 메모리가 가득 차 있는 경우라면 OS는 New 상태에서 Ready/Suspend 상태로 Admit 한다.

### PCB

운영체제가 프로세스를 제어하기 위해 정보(CPU 레지스터 값들)를 저장해 놓는 곳으로 프로세스의 상태 정보를 저장하는 구조체이다. 프로세스 생성시 PCB 가 만들어지며 주기억장치에 저장되다가 프로세스가 완료되면 PCB도 함께 제거된다.

- 운영체제에서 프로세스는 PCB 로 표현된다.
- PCB는 프로세스 상태 관리와 context switching 을 위해서 필요하다.
- PCB 는 프로세스의 중요한 정보들을 담고 있으므로 일반 사용자는 접근하지 못하는 보호된 메모리 영역에 존재한다.

### 구성요소

### 포인터

- 프로세스의 현재 위치를 저장하는 포인터 정보

### 프로세스 상태

- 프로세스의 상태 (생성, 준비, 실행, 대기, 종료) 에 대한 정보를 저장

### 프로세스 식별자

- 모든 프로세스에는 각 프로세스를 식별하는 고유한 ID, PID 가 할당

### 프로그램 계수기(프로그램 카운터)

- 프로세스가 실행해야 하는 다음 명령어의 주소

### 레지스터

- 누산기, 베이스, 레지스터 및 범용 레지스터를 포함하는 CPU 레지스터에 있는 정보

### 메모리 제한

- 운영 체제에서 사용하는 메모리 관리 시스템에 대한 정보가 포함
- 페이지 테이블, 세그먼트 테이블 등이 포함될 수 있음

**페이징, 세그멘테이션 활용 시**

CPU는 논리 주소로 프로그램이 설정한대로 연속적인 주소값으로 명령 -> 이는 각 프로세스의 PCB 에 저장되어 있는 페이지 테이블/ 세그먼트 테이블 -> 페이지/세그먼트의 실제 메모리 주소(물리 주소)로 변경됨!

운영체제는 빠르게 PCB 에 접근하기 위해서 **프로세스 테이블**을 사용해 각 프로세스의 PCB 를 관리하고 PCB 는 **연결 리스트 방식**으로 관리된다. 프로세스가 생성, 삭제될 때 PCB 의 삽입 삭제가 용이하다.

### 컨텍스트 스위칭

CPU가 현재 작업중인 프로세스에서 다른 프로세스로 넘어갈 때, 이전의 프로세스 정보를 PCB에 저장하고 새롭게 실행할 프로세스의 정보를 PCB에서 읽어와 레지스터에 적재하는 과정을 말한다.

## Context

- 프로세스의 데이터
- CPU 레지스터 값

CPU 가 프로세스를 실행시키기 위해 필요한 정보들을 **Context** 라 한다.

프로세스가 메모리에 올라가 실행 될 때 CPU 내에 존재하는 레지스터들이 현재 실행중인 프로세스 관련 데이터로 채워지게 되고 실행중인 프로세스가 변경되면 CPU 내의 레지스터 값들이 변경된다.

## Context Switching 과정

!https://velog.velcdn.com/images/nnnyeong/post/41a70967-180a-4394-a2c8-d8ebf342bb69/image.png

- 요청 발생
    - 인터럽트나 트렙에 의해서 컨텍스트를 바꿔야 한다는 요청이 들어옴
- PCB 에 프로세스 정보 저장
    - 기존에 실행중이던 프로세스 `P0` 와 관련된 정보들을 PCB 에 저장함
- CPU 새롭게 할당
    - 운영체제는 새롭게 실행할 프로세스 `P1` 에 대한 정보를 해당 PCB 에서 가져와 CPU 레지스터에 적재함

## Context Switching의 발생

### 멀티 태스킹

실행 가능한 여러개의 프로세스들이 운영체제의 스케쥴러에 의해, 우선순위에 따라 조금씩 번갈아가면서 수행된다. CPU를 할당 받는 프로세스가 변경될 때 마다 컨텍스트 스위칭이 일어난다.

### 인터럽트 핸들링

컴퓨터 시스템에서 예외 상황이 발생했을 때 이를 CPU 에게 알려 실행중이던 프로세스 정보를 저장하고 발생한 예외 상황을 처리하기 위한 컨텍스트 스위칭이 일어난다.

### 사용자모드 커널모드 전환 (User and Kernel mode Switching)

- context switching 이 필수는 아니지만 운영체제에 따라 발생 가능하다.

**[ 프로세스 컨텍스트 스위칭 (Process Context Switching) / 스레드 컨텍스트 스위칭 (Thread Context Switching) ]**

**1) 공통점**

- 커널 모드에서 실행
- CPU의 레지스터 상태를 교체

**2) 차이점**

- 프로세스 컨텍스트 스위칭
    - 서로 다른 프로세스에 속한 스레드 간의 컨텍스트 스위칭 발생
    - 가상(virtual) 메모리 주소 관련 처리를 추가로 수행 / MMU, TLB 다시 세팅해야 함
- 스레드 컨텍스트 스위칭
    - 같은 프로세스에 속한 스레드 간의 컨텍스트 스위칭 발생

### **✔️ Point2 : 스레드 컨텍스트 스위칭이 더 빠른 이유**

메모리 주소 관련 처리를 하지 않기 때문이다.

> - 현재 실행 중인 프로세스 혹은 스레드의 context 백업 (가령, CPU 레지스터 값들, 어디까지 실행됐는지 등)
>

프로세스 컨텍스트 스위칭은 위 4가지 모두 수행하지만, 스레드 컨텍스트 스위칭은 첫번 째만 수행하면 된다.

💁‍♀️ **서로 다른 프로세스** : 서로 다른 메모리 주소 공간(memory address space)

💁‍♂️ **같은 프로세스 내 스레드** : 소속된 프로세스의 메모리 주소 공간 공유

그래서 프로세스가 바뀔 때  새로 실행되는 프로세스가 기존에 실행되는 프로세스의 메모리 주소 공간에 침범하면 안 되기 때문에 추가적인 작업이 필요하다.

그래서 **프로세스 컨텍스트 스위칭 작업이 더 오래 걸린다.**

컨텍스트 스위칭 오버헤드는 대표적으로 다음과 같은 행위에 의해서 발생된다.

1. PCB 저장 및 복원 비용
2. CPU 캐시 메모리 무효화에 따른 비용
3. 프로세스 스케줄링 비용

### 프로세스 컨텍스트 스위칭 vs 스레드 컨텍스트 스위칭

프로세스 컨텍스트 스위칭과 스레드 컨텍스트 스위칭은 모두 멀티태스킹 환경에서 여러 프로세스 또는 스레드를 동시에 실행하기 위한 기술이다. 그러나 두 기술은 몇 가지 차이점이 있다.

1. TCB가 PCB보다 가볍다

결론부터 말하자면, 스레드 컨텍스트 스위칭이 프로세스 컨텍스트 스위칭보다 더 빠르다.

위에서 프로세스와 스레드의 메모리 섹션에서 다뤘듯이, 프로세스 내의 스레드들은 text, data, heap 영역 메모리를 공유하기 때문에 TCB에는 stack 및 간단한 register 포인터 정보만을 저장하기 때문에 PCB보다 TCB가 가벼워 더 빨리 읽고 쓸수 있다.

!https://blog.kakaocdn.net/dn/bX1zDN/btr7Pj57YmU/dOnxKJqOLBwdYd4SYlsiH0/img.png

1. 캐시 메모리 초기화 여부

CPU 캐쉬 메모리는 CPU와 메인 메모리 사이에 위치하며 CPU에서 한번 이상 읽어들인 메모리의 데이터를 저장하고 있다가, CPU가 다시 그 메모리에 저장된 데이터를 요구할 때, 메인 메모리를 통하지 않고 곧바로 데이터를 전달해 주는 용도이다. 그런데 프로세스 컨텍스트 스위칭이 일어날 경우, 다른 프로세스의 실행으로 인해 CPU가 새로운 명령어와 데이터를 로드해야 하기 때문에 CPU 캐시 메모리를 초기화 하여야 한다. 이것이 프로세스 컨텍스트 스위칭에 부담이 되는 요소이다.

스레드 컨텍스트 스위칭일 경우, 프로세스 내 스레드 간에 스택과 레지스터 값 등 일부 컨텍스트 정보만 변경되므로 CPU 캐시 메모리는 초기화되지 않는다. 다만 스레드가 다른 CPU 코어에서 실행될 때는 해당 코어의 캐시 메모리에 스레드 컨텍스트 정보가 로드되어야 하므로 초기화될 수 있다.

1. 자원 동기화 문제

스레드 컨텍스트 스위칭이 발생해 다른 스레드가 heap 영역의 공유 데이터에 접근할때, 이전 스레드가 이미 공유 자원을 사용하고 있는 경우 동기화 문제가 발생할 수 있다. 예를 들어, 두 개의 스레드가 동시에 하나의 변수를 수정하려고 할 때, 스레드 컨텍스트 스위칭이 발생하면 변수의 값을 잘못된 값으로 업데이트 할 수 있는 것이다. 이것을 스레드 간에 경쟁 조건 (race condition)이라고 한다.

프로세스는 기본적으로 독립된 공간이지만, IPC와 같은 공유 자원을 사용하는 경우에 똑같이 경쟁 조건이 발생 할 수가 있다. 예를 들어, 여러 개의 프로세스가 동시에 파일 시스템에 접근하여 파일을 수정하려고 할 때, 컨텍스트 스위칭이 발생할 때 다른 프로세스가 그 파일에 접근할 수 있기 때문에 파일 내용이 손상될 수 있다.따라서 이들을 해결하기 위해선 각 상황에 적절한 공유 자원에 대한 동기화 메커니즘이 필요해진다.

### 스레드

프로세스가 할당받은 자원을 이용하는 **실행 흐름**의 단위이다. 스레드는 운영체제의 스케줄러에 의해 독립적으로 관리될 수 있는 프로그래밍된 명령어의 가장 작은 시퀀스이다. 하나의 프로세스는 하나 이상의 스레드를 갖고 있다.

### 쓰레드의 장단점

장점

- 컨텍스트 스위칭 시 스레드 공유 영역(Code~Heap)은 올리고 내릴 필요가 없다.
- Data와 Heap 영역을 스레드끼리 공유할 수 있어서 중복된 데이터만큼 자원(메모리)을 아낄 수 있다.
- 다중 CPU 구조에서는 각각의 스레드가 다른 프로세서에서 병렬로 수행될 수 있으므로 병렬성이 증가한다.

단점

- 둘 이상의 쓰레드가 하나의 변수에 접근하려고 할 때 문제가 발생할 수 있다. (임계영역)
- 쓰레드 하나가 프로세스 내의 자원을 망친다면 프로세스 종료될 수 있다. 프로세스가 종료되면 그 안에 실행되고 있던 스레드는 모두 강제종료된다.

### 스레드 상태

프로세스 상태와 마찬가지로, 스레드에도 상태가 있다. 일반적으로 다음과 같은 4가지 상태를 가진다.

- NEW : 스레드가 생성되고 아직 호출되지 않은 상태
- RUNNABLE : 스레드가 실행되기 위해 기다리는 상태. CPU를 할당받을 수 있는 상태이며, 언제든지 실행될 준비가 되어있다.
- BLOCKED : 스레드가 특정 이벤트(입출력 요청 등)가 발생하여 대기하는 상태
  CPU를 할당받지 못하며, 이벤트가 발생하여 다시 RUNNABLE 상태로 전환될 때까지 대기한다.
- TERMINATED : 스레드가 실행을 완료하고 종료된 상태. 더 이상 실행될 수 없으며, 메모리에서 제거된다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/f161c15f-c5f0-4683-9793-c7551a62792f/82dee5e9-e2c1-409d-85b8-727b7fdaa1e2/Untitled.png)

Code 영역부터 Heap 영역까지는 모든 스레드가 공유하고 Stack 영역만 각각 사용한다.

### 동시성과 병렬성

쓰레드 처리 방식 중에 동시성과 병렬성이 있다.

두개의 쓰레드를 처리해야한다고 가정하자.

동시성은 하나의 코어에서 두개의 쓰레드를 매우 빠른 속도로 마치 동시에 실행하는 것처럼 번갈아가면서 처리한다

병렬성은 두개의 코어에서 각각 하나의 쓰레드를 맡아 진짜 동시에 처리하는 것을 말한다.

### 동시성이 필요한 이유

그런데 상식적으로 생각해보면 동시성(Concurrency)은  '동시에 돌아가는 것 처럼' 보이는 거지, 정말 실제로 동시에 돌아가는 것이 아니기 때문에 최종 작업이 걸리는 시간은 거의 차이가 없을 것이다. 병렬성은 정말로 각 코어에 프로세스를 나눠 실행하는 거니까 듀얼 코어면 반 이상 줄어들텐데 말이다. 그렇다면 왜 이렇게 번거롭게 작업들을 스위칭 하며 처리하는 것일까?

1. 첫번째는하드웨어적 한계 때문이라고 할 수있다. CPU 발열 때문에 깡 클럭으로 성능을 올리기에는 한계에 봉착됬기 때문에 코어의 성능을 올리는 대신 코어를 여러개 탑재하여 쿼드 코어, 옥타 코어 CPU들을 출시하고 있다. 하지만 아무리 코어를 많이 넣어도 수십개의 코어를 넣은순 없으니 결국 하드웨어적 제한이 걸리게 되고 수십수백개의 프로세스를 돌리기 위해선 결국 동시성이 필요한 것이다.
2. 두번째는 보다 논리적/효율적인 이유에서이다. 4코어 8스레드의 CPU 환경에서 현재 총 16개의 작업이 있다고 가정을 해보자. 그중 8개는 오래 걸리는 작업이고, 나머지 8개는 짧은 시간을 필요로 하는 작업이라고 한다. 논리적인 8개의 코어이니 최대 8개까지 동시에 실행할수 있을텐데, 만일 최악의 경우 8개의 오래 걸리는 작업이 먼저 동시에 처리되기 시작했다고 하자. 이 경우 나머지 가벼운 8개의 작업은 처리하는데 짧은 시간이 걸리는 데에도 불구하고 현재 처리중인 8개의 작업이 다 끝날때 까지 기다려야 할 것이다. 따라서 이러한 비효율적인 면을 극복하기 위해 작업을 아주 잘게 나눠 번갈아 가면서 처리하는 동시성 개념을 채택한 것이다.따라서 최대 8개의 작업에 대해서 8개의 논리적인 스레드가 병렬적으로 아주 빠르게 동시적으로 작업을 하면서, 그보다 많은 수십개의 소프트웨어적 스레드가 있다면 적절히 병렬성과 동시성을 섞어 동시에 돌리게 되게 된다.

### 멀티 프로세스 vs 멀티 스레드

| 프로세스 | 스레드 |
| --- | --- |
| 운영체제로부터 자원을 할당받은 작업의 단위 | 프로세스가 할당받은 자원을 이용하는 실행 흐름의 단위 |

### 멀티 프로세스

### 멀티 프로세스의 장점

1. 프로그램 안전성

멀티 프로세스는 각 프로세스가 독립적인 메모리 공간을 가지므로, 한 프로세스가 비정상적으로 종료되어도 다른 프로세스에 영향을 주지 않는다. 그래서 프로그램 전체의 안전성을 확보할 수 있다는 장점이 있다.

예를 들자면 크롬 브라우저에서 여러개의 탭을 띄우고 여러곳의 웹사이트를 방문해 서비스를 이용한다고 하자. 이때 어느 한 탭의 웹사이트에서 무언가 잘못되어 먹통이 되었다.

아주 심각한 오류가 아닌 이상, 당장 그 브라우저 탭의 웹사이트는 이용을 못하겠지만, 다른 탭은 별 문제없이 이용이 가능할 것이다. 이러한 이유는 자식 프로세스가 여러개 생성되어 메모리에 별도로 관리되기 때문이다.

1. 프로그램 병렬성

멀티 프로세스와 여러개의 CPU 코어를 활용하여 둘의 시너지를 합쳐, 다중 CPU 시스템에서 각 프로세스를 병렬적으로 실행하여 성능을 향상 시킬 수 있다. 예를 들어 이미지 처리나 비디오 인코딩과 같은 작업을 여러 개의 코어나 CPU에 분산시켜 빠르게 처리할 수 있다.

다만, 이 부분은 멀티 프로세스 만의 장점이라기 보단, 멀티 프로세스와 멀티 스레드 둘의 장점이 옳다. 그리고 멀티 스레드로 구성하는 것이 멀티 프로세스로 구성하는 것보다 훨씬 효율적이고 빠르기 때문에, 멀티 프로세스로 성능을 올리는 행위는 거의 없다고 보면 된다. 이에 대해선 뒤의 멀티 스레드 파트에서 다시 다룬다.

1. 시스템 확장성

멀티 프로세스는 각 프로세스가 독립적이므로, 새로운 기능이나 모듈을 추가하거나 수정할때 다른 프로세스에 영향을 주지 않는다. 그래서 시스템의 규모를 쉽게 확장할 수 있다.

이 부분에 대해서는 컴퓨터의 소프트웨어로 예시를 드는 것보다 네트워크의 서버(server)로 드는 것이 적절하기 때문에 잠시 분산 서버에 대해서 말해보겠다. 대규모 웹 서비스에서는 수많은 요청을 동시에 처리하기 위해 여러대의 서버를 두고 로드 밸런서(Load Balancer)와 같은 장비를 사용하여 클라이언트 요청 트래픽을 분산 시킨다. 이때 여러대의 서버는 컴퓨터를 여러개를 말하는 것일 수도 있고, 하나의 성능 좋은 컴퓨터에 여러개의 서버 프로세스를 두는 것을 말하기도 한다. 멀티 프로세스의 상황은 후자이다.

서버 프로그래밍을 해본 백엔드 개발자분들은 서버 클러스터(cluster)를 구성해본 적이 있을 것이다. 하나의 컴퓨터에 여러개의 서버 프로세스를 띄움으로써 요청을 분산시키는 것이다. Node.js 진영에선 대표적으로PM2Visit Website 가 있다.이렇게 멀티 프로세스를 사용하여 여러 대의 서버에 요청을 분산시켜 처리함으로써, 시스템의 규모를 쉽게 확장할 수 있으며, 부가로 서버의 장애나 다운타임을 최소화할 수 있게 되는 것이다.

### 멀티 프로세스의 단점

1. Context Switching Overhead

   !https://blog.kakaocdn.net/dn/c8hWqD/btr6rw5WrBY/6Zun2QryWJBoiyh4FGrqCk/img.png


멀티 태스킹(multi tasking)Visit Website을 구성하는데 핵심 기술인 컨텍스트 스위칭(context switching) 과정에서 성능 저하가 올 수 있다. 특히나 프로세스를 컨텍스트 스위칭 하면, CPU는 다음 프로세스의 정보를 불러오기 위해 메모리를 검색하고, CPU 캐시 메모리를 초기화하며, 프로세스 상태를 저장하고, 불러올 데이터를 준비해야 하기 때문에, 이로 인한 빈번한 Context Switching 작업으로 인해 비용 오버헤드가 발생할 수 있게 된다.

반면 스레드를 컨텍스트 스위칭하면 프로세스 스위칭 보다 가벼워 훨씬 빠르고 좋다.프로세스 1에서 2로 스위칭할때 아주 약간의 빈 시간(오버헤드)가 발생한다.

따라서, 멀티 프로세스 환경에서는 Context Switching Overhead를 최소화하는 방법이 중요하다. 이를 위해서 프로세스 수를 적정하게 유지하거나, I/O 바운드 작업이 많은 프로세스와 CPU 바운드 작업이 많은 프로세스를 분리하여 관리하고, CPU 캐시를 효율적으로 활용하는 등의 방법을 고려해 봐야 한다.

1. 자원 공유 비효율성

   !https://blog.kakaocdn.net/dn/wHlQM/btr53ErRepe/bojoHmQqek8FjkKLY25Zo0/img.png


멀티 프로세스는 각 프로세스가 독립적인 메모리 공간을 가지므로, 결과적으로 메모리 사용량이 증가하게 된다.만일 각 프로세스간에 자원 공유가 필요할 경우 프로세스 사이의 어렵고 복잡한 통신 기법인 IPC(Inter-Process Commnuication)을 사용하여야 한다.
IPC란 운영체제 상에서 실행 중인 프로세스 간에 정보를 주고받는 메커니즘을 말한다. 이를 위해 파이프, 소켓, 메세지 큐 등 다양한 방법이 사용된다. 그런데 IPC 자체로 오버헤드가 발생한다. 예를 들어, 파이프나 소켓과 같은 IPC 기법은 데이터를 복사하거나 버퍼링하는 과정에서 성능 저하가 발생할 수 있기 때문이다. 또한 코드의 복잡도를 증가시킨다.

### 멀티 스레드

### 멀티 스레드의 장점

윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레딩을 기본으로 하고 있다.왜 멀티 프로세스 보다 멀티 스레드로 프로그램을 돌리는 것이 유리한지 그 이유에 대해 알아보자. (이는 스레드 자체의 장점이기도 하다)

1. 스레드는 프로세스보다 가벼움

일단 스레드는 프로세스 보다 용량이 가볍다. 그도 그럴게 스레드는 프로세스 내에서 생성되기 때문에 스레드의 실행 환경을 설정하는 작업이 매우 간단하여 생성 및 종료가 빠르다. 또한 스레드는 프로세스와 달리, 코드, 데이터, 스택 영역을 제외한 나머지 자원을 서로 공유하기 때문에 기본적으로 내장되어 있는 데이터 용량이 프로세스보다 당연히 작다. 그래서 스레드를 생성하고 제거할 때, 프로세스 내부의 자원만을 관리하면 되기 때문에 프로세스 생성, 제거 보다 훨씬 빠른 것이다.

1. 자원의 효율성

   !https://blog.kakaocdn.net/dn/bilJ94/btr6rxcJ12e/yGcKc7yuB3nDWXWso0l3T0/img.png


멀티 스레드는 하나의 프로세스 내에서 여러 개의 스레드를 생성되기 때문에, heap 영역과 같은 공유 메모리에 대해 스레드 간에 자원을 공유가 가능하다. 이를 통해, 프로세스 간 통신 (IPC)을 사용하지 않고도 데이터를 공유할 수 있기 때문에, 자원의 효율적인 활용이 가능해 시스템 자원 소모가 줄어든다.

1. Context Switching비용 감소

   !https://blog.kakaocdn.net/dn/PpwcB/btr73xQQciT/mosSUj7hHNLFKQ4s3sXPK1/img.jpg


스레드에도 컨텍스트 스위칭 오버헤드가 존재한다. 하지만 상대적으로 프로세스 컨텍스트 스위칭 오버헤드보다 훨씬 낮아 비용이 낮다는 장점이 있다. 프로세스 컨텍스트 스위칭 비용은 스위칭할 때마다 CPU 캐시에 있는 내용을 모두 초기화하고, 새로운 프로세스 정보를 CPU 캐시에 적재해야 하므로 높은 비용이 든다. 반면, 스레드 컨텍스트 스위칭 비용은 스위칭할 때 스레드 간에 공유하는 자원을 제외한 스레드 정보(stack, register)만을 교체하면 되므로 프로세스 컨텍스트 스위칭 비용보다 상대적으로 낮은 것이다.

1. 응답 시간 단축

앞의 멀티 스레드의 장점을 종합해보자면, 멀티 스레드는 스레드 간의 통신이나 자원 공유가 더욱 용이하며, 프로세스 보다 가벼워 컨텍스트 스위칭 오버헤드도 작다. 따라서 멀티 프로세스 보다 응답 시간이 빠르다.예를 들어, 웹 서버에서 클라이언트 요청을 처리하는 경우, 멀티 프로세스 방식에서는 각 요청마다 프로세스를 생성하여 처리해야 하므로, 오버헤드가 크지만, 멀티 스레드 방식에서는 여러 개의 스레드가 하나의 프로세스 내에서 요청을 처리할 수 있으므로, 오버헤드가 감소해 더욱 빠른 응답 시간을 보장할 수 있는 것이다.이러한 이유로, 멀티 프로세서 환경에서 멀티 스레드를 사용하여 작업을 처리하는 것이 멀티 프로세스를 사용하는 것보다 더 효율적이다라고 말할 수 있다.

### 멀티 스레드의 단점

1. 안정성 문제

   !https://blog.kakaocdn.net/dn/L5gYp/btr6eUGAI4R/9UC9f5ZWqb9TakHZWmCc30/img.png


멀티 프로세스 모델에서는 각 프로세스가 독립적으로 동작하므로 하나의 프로세스에서 문제가 발생해도 다른 프로세스들은 영향을 받지 않기 때문에 프로그램이 죽지 않고 계속 동작할 수 있다. 그러나 멀티 스레드 모델에서는 기본적으로 하나의 스레드에서 문제가 발생하면 다른 스레드들도 영향을 받아 전체 프로그램이 종료될 수 있다. 물론 이는 프로그래머의 역량에 따라 극복할 수 가 있다. 예를 들어 스레드에 에러가 발생할 경우 이에 대한 적절한 예외 처리를 잘 해놓는다던지, 에러 발생 시 새로운 스레드를 생성하거나 스레드 풀(Thread Pool)에서 잔여 스레드를 가져오던지 하여 프로그램 종료를 방지할 수 있다. 다만, 이때 새로운 스레드 생성이나 놀고 있는 스레드 처리에 추가 비용이 발생하게 된다.

1. 동기화로 인한 성능 저하

   !https://blog.kakaocdn.net/dn/bmehI6/btr736r6Tw6/wTH0UPpQfmgkgozqmiwte1/img.png


멀티 스레드 모델은 여러 개의 스레드가 공유 자원에 동시에 접근할 수 있기 때문에, 동기화 문제가 발생할 수 있다. 예를 들어 여러 스레드가 동시에 한 자원을 변경해 버린다면 의도되지 않은 엉뚱한 값을 읽어 서비스에 치명적인 버그가 생길수도 있다. 따라서 스레드 간 동기화(syncronized)는 데이터 접근을 제어하기 위한 필수적인 기술이다.동기화 작업은 여러 스레드들이 자원에 대한 접근을 순차적으로 통제하는 것이다. 그러면 동시 접근으로 인한 동시 수정과 같은 현상은 일어나지 않게 된다. 그러나 동기화 작업은 여러 스레드 접근을 제한하는 것이기 때문에병목 현상이 일어나 성능이 저하될 가능성이 높다는 단점이 있다.

이를 해결하기 위해 임계 영역(Critical Section)에 대하여 뮤텍스(mutex), 또는 세마포어(Semaphore) 방식을 활용한다.

> 임계 영역(Critical Section)- 멀티 스레드 프로그래밍에서 임계 영역은 공유 자원을 접근하는 코드 영역을 말한다. 대표적으로 전역 변수나 heap 메모리 영역을 들 수 있겠다.
뮤텍스(Mutex)- 공유 자원에 대한 접근을 제어하기 위한 상호 배제 기법 중 하나로, 임계 영역에 진입하기 전에 락(lock)을 획득하고, 임계 영역을 빠져나올 때 락을 해제하여 다른 스레드들이 접근할 수 있도록 한다. 한마디로 오직 1개의 스레드만이 공유 자원에 접근할 수 있도록 제어하는 기법이다.
세마포어(Semaphore)- 세마포어는 동시에 접근 가능한 스레드의 개수를 지정할 수 있다. 세마포어 값이 1이면 뮤텍스와 동일한 역할을 하며, 값이 2 이상이면 동시에 접근 가능한 스레드의 수를 제어할 수 있다. 스레드가 임계 영역에 진입하기 전에 세마포어 값을 확인하고, 값이 허용된 범위 내에 있을 때만 락을 획득할 수 있는 형식이다. 한마디로 뮤텍스 상위 호환 이라고 보면 된다.
>
1. 데드락 (교착 상태)

   !https://blog.kakaocdn.net/dn/bgRSP9/btr6ouO1S99/B3N1ylkovSB8eUTXKAOKb1/img.png


Deadlock 이란, 다수의 프로세스나 스레드가 서로 자원을 점유하고, 다른 프로세스나 스레드가 점유한 자원을 기다리는 상황에서 발생하는 교착 상태를 말한다. 여러 개의 스레드가 서로 대기하면서 무한정 기다리게되는 무한 루프와 같은 증상이라고 보면된다.

예를들어, 스레드 1 은 자원 A을 점유하고 있는 상태에서 자원 B가 필요한 상황이다. 그리고 스레드 2 는 자원 B를 점유하고 있는 상태에서 자원 A이 필요한 상황이다. 하지만 스레드 1은 자원 B가 필요한 상황에서 자원 A을 빌려줄 수 있는 상황이 아니고, 스레드 2또한 자원 A이 필요한 상태에서 자원 B를 빌려줄 수 없는 상황인 것이다.이처럼 다수의 쓰레드가 같은 lock을 동시에, 다른 명령에 의해 획득하려 할 때 서로 절대 불가능한 일을 계속적으로 기다리는 상황을 이야기 한다.

이러한 현상은 스레드의 특징인 공유 자원에 대한 동시 엑세스로 인한 문제로, 이를 방지하기 위한 상호배제(Mutual Exclusion), 점유와 대기(Hold and Wait), 비선점(No Preemption), 순환 대기(Circular Wait) 등의 알고리즘을 통해 극복해야 한다.

다만, 데드락은 멀티 스레드만의 단점이라기 보다는 멀티 프로세스와 스레드 모델의 공통된 문제점이라고 말하는 것이 옳다. 왜냐하면 프로세스 끼리는 기본적으로 독립적인 메모리 공간이지만 IPC를 통해 공유 자원을 사용할 수 있기 때문에 멀티 스레드와 똑같이 교착 상태에 빠질 수 있기 때문이다.

1. 그래도 Context Switching Overhead

앞서 멀티 프로세스보다 멀티 스레드의 컨텍스트 스위칭 오버헤드가 작아 성능에 유리하다라고 설명했었지만, 그래도 컨텍스트 스위칭 오버헤드 비용 자체를 무시할수는 없다.

특히나 스레드 수가 많으면 많을 수록 그만큼 컨텍스트 스위칭이 많이 발생되게 되고 당연히 이는 성능 저하로 이어진다.이 부분은 '스레드를 많이 쓸수록 항상 성능이 좋아질까?' 라는 물음으로 던질 수 있다. 보통 사람들이 생각하기에는 스레드가 많으면 많을 수록 그만큼 동시 처리수가 늘어나 당연히 스레드가 많으면 무조건 좋다고 이야기할 것이다.

하지만 '컨텍스트 스위칭 오베허드'라는 개념을 알고 있는 개발자인 우리들은 '과연 꼭 그럴까?' 라는 의문을 던져야 한다.이 부분은 스레드를 겉핥기로만 배운 지원자를 걸러내기 위해 기술 면접에서 가끔 등장하는 고수준의 질문이기도 하다.

1. 디버깅이 어려움

   !https://blog.kakaocdn.net/dn/sxYJz/btr76ZeA0uk/UZQiQEy8Ki1jcnH5AzsmP1/img.png


멀티 스레드를 사용하면, 여러 개의 스레드가 동시에 실행되기 때문에, 각 스레드의 동작을 추적하기 어려울 수 있다. 예를들어 코드를 디버깅하는 도중에 다른 스레드가 실행되어 예기치 않은 결과가 발생할 수 있다. 또한 어떤 스레드가 언제 어떤 자원에 접근하고, 어떤 순서로 실행되는지 등을 파악하기 어려울 수 있다.따라서 스레드 간의 상호작용과 동기화 기법을 잘 이해하고, 디버깅 도구를 적극적으로 활용해야 한다.

1. 운영체제의 지원이 필요

오늘날의 윈도우, 리눅스, 맥 OS에선 모두 기본적으로 멀티 스레딩을 기본적으로 지원하도록 설계 되었으니 문제점이라기에는 약간 어폐가 있긴 하다. 하지만, 1980년대의 SunOS3와 같은 오래된 유닉스 시스템에는 스레드가 없었고 프로세스만 있는, 멀티 스레딩을 지원하지 않는 운영 체제가 있었기 때문에 멀티 스레드의 단점으로 넣어 보았다. (그만 잊어도 된다 😅)

프로세스 자원 공유는 단순히 CPU 레지스터 교체뿐만이 아니라 RAM과 CPU 사이의 캐시 메모리까지 초기화되기 때문에 자원 부담이 크다는 단점이 있다.

그래서 다중 작업이 필요한경우 스레드를 이용하는 것이 훨씬 효율적이라, 현대 컴퓨터의 운영체제에선 다중 프로세싱을 지원하고 있지만 다중 스레딩을 기본으로 하고 있다.

### 인터럽트

### 인터럽트란

**CPU가 특정 기능을 수행하는 도중에 급하게 다른 일을 처리하고자 할 때 사용할 수 있는 기능**

이다.

대부분의 컴퓨터는 한 개의 CPU를 사용하므로 한 순간에는 하나의 일 밖에 처리할 수 없기 때문에

**어떤 일을 처리하는 도중에 우선 순위가 급한 일을 처리할 필요가 있을 때 대처할 수 있는 방안**

이 필요하다.

예를 들면, 키보드의 키를 하나 누르면, 눌려진 키 코드 값이 키보드 버퍼에 입력된 후 CPU에 인터럽트가 걸린다. 그럼 현재 처리하던 작업에 대한 정보를 수집하여 저장한 뒤에 인터럽트 서비스 루틴(Interrupt Service Routine)을 수행한다.(이 경우에는 키보드 버퍼에 있는 키 코드 값을 가져가는 일을 한다.) 이렇게 인터럽트 처리를 마친 후에는 다시 이전에 처리하던 작업으로 돌아간다.

### 인터럽트는 왜 필요한가?

선점형 스케줄러를 예로 들면 프로세스가 Running 중에 스케줄러에 의해 중단되게 됩니다. 이유는 다른 프로세스로 교체하기 위함이죠. 그렇게 하기 위해서는 스케줄러의 코드가 실행이되서 현재 진행중인 프로세스를 중지시킬 수 있어야 합니다. 스케줄러도 하나의 프로그램이니까요.

프로세스가 스스로 결정하는것은 진행 중에 I/O장치 혹은 다른 작업을 진행해야 해서 Block 상태가 되는것과 프로세스가 종료되서 Exit상태가 되는것이지 Running 상태에서는 스케줄러에의해 강제로 Ready상태가 되는겁니다. 프로세스가 스스로 중단하는것이 아니라 스케줄러가 강제로 중단을 시키는것이고 인터럽트는 이러한 부분에서도 필요한 기능입니다.

- 외부 인터럽트: 입출력 장치, 타이밍 장치, 전원 등의 외부적인 요인에 의해서 발생하는 인터럽트.
    - 전원 이상 인터럽트: 정전이나 전원이 이상이 있는 경우
    - 기계 고장 인터럽트: CPU등의 기능적인 동작 오류가 발생한 경우
    - 입출력 인터럽트(I/O Interrupt): 입출력의 종료 등의 이유로 CPU의 수행을 요청하는 인터럽트.
- 내부 인터럽트: 잘못된 명령이나 데이터를 사용할 때 발생하는 인터럽트
    - 0으로 나누는 경우
    - 오버플로우 또는 언더플로우가 발생한 경우
    - 프로그램 상의 오류
    - 프로그램에서 함수 등 명령어를 잘못 사용한 경우
    - 소프트웨어 인터럽트: CPU가 인스트럭션을 수행하는 도중에 일어나는 인터럽트

> 내부 인터럽트 === 소프트웨어 인터럽트
외부 인터럽트 === 하드웨어 인터럽트
>

### 1. 0으로 나누는 경우

**Divide - dy - Zero Interrupt**

```c
#include <stdio.h>int main() {
    printf("Hello World!\n");
    int data;
    int divider = 0;
    data = 1 / divider; // 해당 부분에서 인터럽트가 발생합니다.
    return 0;
}
```

위의 코드를 실행시켰을 때 결과를 먼저 보겠습니다.

```
Hello World!
Floating point exception (core dumped) // 이 오류는 나누기를 할 때 변수/0이 있으면 발생
```

위와 같이 간단한 코드는 컴파일 하는 과정에서는 에러가 나지 않지만 실행시켰을시에 결과는 `Hello Wordl!`가 나오고 위와 같은 오류를 표시합니다. 바로 운영체제에서 보여주는 오류인데 주석의 내용과 같이 변수/0을 계산할 수 없기 때문에 변수/0의 인터럽트가 발생하고 운영체제는 사용자에게 인터럽트에게 받은 정보를 보여주는겁니다.

### 2. 타이머 인터럽트 | 선점형 스케줄러를 위해 필요

!https://velog.velcdn.com/images%2Fhyun0310woo%2Fpost%2F655f3426-913f-4a8a-be08-b598cb8de619%2FUntitled.png

**타이머 인터럽트를 발생시키는 장치가 컴퓨터 안에 칩으로 존재**하는데 해당 칩에서 **일정 간격으로 인터럽트를 계속해서 발생**시킵니다. 여기서는 1초 주기로 발생시킨다고 가정하겠습니다.

그러면 하드웨어에서는 1초 간격으로 운영체제에게 인터럽트를 발생시키고 그것을 받은 운영체제는 **해당 인터럽트를 누적**시켜서 가지고 있습니다.

여기서 우리가 선점형 스케줄러를 사용한다고 가정했을때 10초마다 **프로세스를 교체한다고 한다면 운영체제는 하드웨어로부터 받은 인터럽트의 누적이 10초가 되는 순간 프로세스를 교체**해야 한다는 시기를 알 수 있습니다. 이것이 외부 인터럽트 처리 방법이고 선점형 스케줄러에게 필요한 기능입니다.

### 3. 입출력 인터럽트 | I/O Interrupt

다음은 입출력 인터럽트입니다. 그 종류도 매우 다양한텐데 기본적으로 키보드, 마우스, 저장장치, 프린터 등등 많겠지만 마우스로 예를 들면 마우스가 클릭이 될때마다 그것을 운영체제에게 알려줘야 할텐데 그것을 알려주는 인터럽트가 입출력 인터럽트라고 생각하면 됩니다.

## 인터럽트 그리고 IDT(Interrupt Descriptor Table)

위에도 언급했지만 인터럽트는 각각의 고유 번호가 미리 정의되어 있습니다. 그래야 이전에 이야기했었던 수 많은 이벤트들을 각각 어떻게 처리할지 알 수 있으니까요. 그리고 수 많은 이벤트들을 어떻게 처리해야하는지에 대한 코드들이 운영체제에 구현이 되어있습니다. 그리고 해당 코드들은 IDT에 기록이 되어있습니다.

IDT에 기록이 되어 있는건 알겠는데 언제 기록을 하나? 어쨋든 해당 기록되어 있는 코드들을 사용하려면 프로세스의 실행보다 먼저 기록이 되어있어야 하기때문에 컴퓨터는 부팅시에 바로 운영체제가 해당 기록을 하기 시작합니다. 그리고 당연히 내부에서 실행하는 코드이기 때문에 커널 영역에 위치하게 됩니다.

### 동기적 인터럽트, 비동기적 인터럽트

### 동기적 인터럽트

프로세스가 실행 중인 명령어로 인해 발생하는 인터럽트를 **동기적 인터럽트(내부 인터럽트)**라 한다.

- 프로그램상의 문제로 인해
- 작업자가 의도적으로
- 입출력장치 같은 주변장치의 조작에 의한
- 산술연산중 발생

### 비동기적 인터럽트

그리고 다른 하드웨어 장치가 실행 중인 명령어와 무관하게 생성하는 인터럽트를 **비동기적 인터럽트(외부 인터럽트)**라 한다.

- 하드디스크 읽기 오류
- 메모리 불량과 같은 하드웨어적인 오류
- 사용자가 직접 작동하는 키보드 인터럽트, 마우스 인터럽트

+) 보통 동기적인 인터럽트를 예외(Exception), 비동기적인 인터럽트를 인터럽트라고 한다,

### 인터럽트 처리 과정

### 인터럽트 처리 과정

1. **인터럽트 요청**
2. **프로그램 실행 중단:** 현재 실행중이던 Micro operation 까지 수행
3. **현재의 프로그램 상태 보존:** PCB(Process Control Block), PC(Program Counter) 등
4. **인터럽트 원인 판별:**
    - 인터럽트를 요청한 장치를 식별
    - Interrupt Vector 테이블을 참조하여 호출할 ISR 주소 값을 얻는다.
5. **ISR(Interrupt Service Routine) 실행**
    - 인터럽트 발생시 실행할 함수
    - 실질적인 인터럽트 처리 작업 수행
    - 서비스루틴 수행 중 우선순위가 더 높은 인터럽트가 발생하면 또 재귀적으로 1~5를 수행한다.
    - 인터럽트 서비스 루틴을 실행할 때 인터럽트 플래그(IF)를 0으로 하면 인터럽트 발생을 방지할 수 있다.
6. **상태복구 :** 인터럽트 발생 시 저장해둔 PC(Program counter)를 다시 복구하여 이전 실행 위치로 돌아간다.
7. **중단된 프로그램 실행 재개:** PCB의 값을 이용하여 이전에 수행중이던 프로그램을 재개한다.

### 운영체제 이중 동작 모드

이중 동작 모드란 다중 프로그래밍 환경에서 운영체제를 보호하는 보안 기법이다. 응용 프로그램이 운영체제의 자원(메모리, CPU, 하드디스크 등)에 직접 접근하는 것을 방지하기 위해 유저 모드(User mode), 커널 모드(Kernel mode) 두 가지 모드로 분리되어있다. CPU는 두 가지 모드에서 명령어를 실행할 수 있는데 요청에 따라 모드를 전환한다.

### 이중동작모드 과정

1. 실행중인 프로그램(유저모드)
2. 인터럽트 발생 후 CPU로 인터럽트 신호 요청(유저모드)
3. CPU에서 모드 플래그를 0으로 변경(커널모드)
4. 해당 하드웨어 인터럽트 서비스 루틴으로 이동(커널모드)
5. 인터럽트 처리(커널모드)
6. 인터럽트 처리 후 CPU의 모드 플래그를 1로 변경(유저모드)
7. 원래의 애플리케이션 위치로 복귀(유저모드)

이중 모드는 운영체제 기능 중에서 보호에 해당된다. 운영체제에서 보호할 대상은 입출력 장치, 메모리, CPU 총 세 가지가 존재한다.

### 2.1 입출력 장치 보호

여러 정보들은 입출력 장치를 통해 컴퓨터로 입력되고, 외부 장치로 출력이 된다. 여기서 크게 두 가지의 문제점이 발생한다.

- 여러 입출력 장치의 사용으로 인한 혼선
- 사용자가 자신의 데이터가 아닌 다른 사용자의 데이터에 입출력을 하는 일위와 같이 입출력 장치에 여러 사용자의 데이터가 뒤엉켜서 들어오거나 다른 사용자의 데이터에 접근하려는 경우를 막아야 한다.

이를 해결하기 위해 `in`, `out` 과 같은 **입출력 명령을 특권 명령으로** 설정하는 것이다. 즉, 사용자 애플리케이션에서 입출력을 사용하려면 운영체제를 통해서 수행해야한다.(소프트웨어 인터럽트) 여러 프로그램이 동시에 입출력을 사용하려고 하면 운영체제 내부에서 순서를 정하여 혼선을 막아줄 수 있다.

만약 A, B 사용자가 있는 상황에서 A가 B의 데이터를 읽기 위해 운영체제에게 소프트웨어 인터럽트를 발생하였다고 하자. 그러면 운영체제 내부의 해당 ISR로 이동하게 되는데, 여기서 현재 사용자가 해당 데이터가 접근할 수 있는 여부를 판단하는 과정이 있으므로 이는 거부된다.

### 2.2 메모리 보호

메모리에는 운영체제뿐만 아니라 여러 개의 사용자 애플리케이션이 존재한다. 한 애플리케이션이 자신의 메모리 영역이 아닌 운영체제나 다른 애플리케이션의 메모리 영역에 침범하려하면 매우 위험하다.

!https://user-images.githubusercontent.com/34755287/53879655-5c353e80-4052-11e9-8ec6-8b247850f347.png

메모리는 일반적으로 위와 같이 구성되어 있을 것이다. 여기서 user1이 OS나 user2, user3에 접근하는 것을 막아야 한다. CPU는 address bus를 통해 메모리 주소에 접근하게 되는데, user1 프로그램이 실행되는 동안에는 user1이 할당되어 있는 메모리 주소 범위 안인 경우에만 접근하면 될 것이다. 이를 address bus에서 검사하는 것이 가장 효율적일 것이다.

!https://user-images.githubusercontent.com/34755287/53879656-5c353e80-4052-11e9-901c-8fcf9c2b5e56.png

위의 생각으로 나온 것이 **MMU(Memory Management Unit)** 이다. MMU는 위의 그림처럼 address bus 중간에 설치된 하드웨어 칩으로서 두 개의 레지스터를 통해 해당 프로그램의 주소 범위를 저장한다.

예를 들어, User1의 시작 주소는 1024, 끝 주소는 4048이라고 하자. User1이 수행되는 동안 운영체제는 해당 프로그램의 주소 범위를 MMU에 설정(**특권 명령**)하는데, base는 1024, limit는 4048이 될 것이다. 결과적으로 user1이 수행되는 동안에는 이 범위 안의 주소값인 경우에만 address bus를 통과시킨다.

만약 해당 프로그램의 주소 범위 밖의 주소값이 MMU에 들어온다면, MMU에서 **내부 인터럽트** 를 발생시켜 CPU에 신호를 준다. 그러면 CPU는 그에 맞는 ISR로 이동하여 해당 프로그램을 강제로 종료시킨다. 이과 같은 잘못된 메모리 접근을 Segment violation 이라 한다.

### 2.3 CPU 보호

CPU 보호는 사용자의 실수 또는 고의로 인한 CPU 독점을 방지해야 한다. 하나의 프로그램이 CPU를 독점하게 되면 다른 프로그램은 수행되지 못한다.

```cpp
while(n = 1)
{
  // ...
}
```

CPU를 독점하는 가장 대표적인 예는 **무한 반복**이다. 위의 코드를 보면 while문의 조건문이 잘못된 것을 볼 수 있다. 비교 연산자가 아닌 대입 연산자를 사용하여 n값이 1이 되므로 while문의 조건은 TRUE가 된다. 이는 n값이 변하지 않는 이상 무한으로 반복된다.

이를 해결하는 방법은 **Timer를 두어 일정 시간이 지나면 타이머 인터럽트**를 발생시킨다. 인터럽트가 발생하면 반드시 운영체제 내의 ISR로 이동하므로, 해당 ISR에서 각 프로그램의 CPU 점유 시간을 측정하여 적절히 분배되도록 조정한다.

예를 들어, 한 프로그램의 CPU 점유 시간이 비정상적으로 오래 걸리는 경우, 강제로 다른 프로그램으로 CPU를 전환시켜 줄 수 있다.

### 운영체제 이중 동작 모드 필요성

- 잘못된 사용자로부터 운영체제를 보호, 잘못된 사용자 서로를 보호하는 방법을 제공해준다.
- 운영체제 내부에는 **나쁜 영향을 끼칠 수 있는 일부 명령들을 특권명령(privileged instruction)으로 지정**함으로써 **운영체제 자신과 사용자에게 시스템적 보호를 제공**한다.
    - 유저모드에서 불법적인 명령을 실행하지 못하게 해놓음.
    - 이에따라, **하드웨어는 특권명령이 커널모드에만 실행되도록 허용**한다.
    - 유저모드에서 특권명령을 실행하려고 시도하면, 하드웨어는 이를 실행하지 않고, 불법적인 명령으로 간주해 운영체제로 트랩을 건다.
- 커널 모드로 전환하는 명령어가 특권 명령의 한 예이다. 또 다른 예는 입출력 제어, 타이머 관리, 그리고 인터럽트 관리를 위한 명령어들이 있다.
- 불법적인 명령이 이중 동작 모드가 필요한 유일한 이유는 아니다.
    - 만약, 이중 동작 모드가 없다면, 잘못된 사용자 프로그램이 데이터를 운영체제 부분에 덮어 기록함으로써 운영체제를 지워버릴 수 있고, 또한 여러 프로그램이 동시에 한 장치에 기록할 수 있으며, 그 경우 예상치 못한 결과가 발생할 수 있다.

### 프로세스 정보공유

### Multi Process 환경에서 Process간 데이터를 어떻게 주고 받을까?

멀티 프로세스 환경에서 프로세스간 데이터를 주고 받기 위해서 IPC(Inter Process Communication)을 제공한다. 간단하게 IPC는 파이프, 소켓, 파일, 공유 메모리 등이 있고 크게는 공유 메모리와 메시지 전달 방식으로 나뉘게 된다.

### IPC(Inter Process Communication)란?

프로세스는 독립적인 주소 공간을 가지고 있어서 다른 프로세스와 데이터를 주고 받을 수 없는데 이런 문제를 해결하기 위한 기법이다. IPC를 통해 프로세스간 통신이 가능하게 만들어준다.

크게 공유 메모리 방식과 메시지 전달 방식이 있는데 아래서 다룬다.

## 공유 메모리(Shared Memory)

공유 메모리 방식은 프로세스들이 주소 공간의 일부를 공유하고 공유된 메모리 영역에 읽기와 쓰기를 하면서 통신하는 방식이다.

메모리는 **`스택-힙-데이터-코드`**영역으로 이루어져있지만 공유 메모리를 할당 받으면 **`스택-힙-데이터-공유메모리-코드`** 이렇게 메모리 공간에 공유 메모리 공간이 추가가 된다.

### 공유 메모리 형성 과정

공유 메모리가 형성되는 과정은 아래와 같다.

1. 프로세스가 공유 메모리 할당을 커널에 요청
2. 커널이 해당 프로세스에 메모리 공간을 할당

이런 두 과정을 거쳐 공유 메모리 공간이 형성된다.

### 공유 메모리 특징

공유 메모리가 형성되면 공유 메모리에 대한 접근이 일반 메모리 접근과 똑같이 취급되어진다. 한 번 공유 메모리가 형성되면 다음엔 커널의 도움이 없어도 각 프로세스들이 메모리 영역에 접근할 수 있기 때문에 IPC 속도가 빠르다는 특징이 있다.

하지만 프로세스 내의 메모리 공간에 공유 메모리 공간이 할당되어 접근이 수월하고 속도가 빠른 대신 서로 다른 프로세스가 동시에 같은 메모리 위치에 접근하면 일관성 문제가 생기는데 이 문제에 대해서는 커널이 책임지지 않기 때문에 각 프로세스들이 공유 메모리 접근에 대한 동기화 문제를 책임져야 하는 단점이 있다.

## 메시지 전달(Message Passing)

메시지 전달은 공유 메모리와 다르게 무조건 커널을 통해 데이터를 전달한다.(send message와 receive message라는 두 가지 연산을 제공 받는다.)

한마디로 데이터를 전달함에 있어 중간에 커널이 중개 역할을 하는 것이다.

### 메시지 전달 과정

메시지 전달의 과정은 아래와 같다.

1. 프로세스 A가 프로세스 B에게 보낼 데이터를 커널에 보낸다.
2. 커널은 프로세스 A한테 온 메시지를 받고 프로세스 B한테 보내준다.

간단한 과정이다.

### 메시지 전달 특징

메시지 전달은 커널을 무조건 거쳐야 한다는 점 때문에 첫 과정을 제외한 나머지는 직접 메모리에 접근이 가능한 공유 메모리와는 달리 속도가 느리다는 단점이 있다.

하지만 커널이 관여하고 있는 만큼 동시 접근에 대한 충돌을 걱정할 필요가 없어 적은 양의 데이터를 교환하는데 효과적이고 구현이 비교적 쉽다는 장점이 있다.

대표적으로 파이프, 소켓, 메시지 큐 등의 방법이 메시지 전달 방식으로 구현된다.

### ref

- 커널 : [https://velog.io/@ragnarok_code/OS-커널kernel이란](https://velog.io/@ragnarok_code/OS-%EC%BB%A4%EB%84%90kernel%EC%9D%B4%EB%9E%80)
- 시스템콜 : [https://velog.io/@nnnyeong/OS-시스템-콜-System-Call](https://velog.io/@nnnyeong/OS-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%BD%9C-System-Call)
- 프로세스 : https://velog.io/@impala/OS-Process
- 프로세스 상태 :https://velog.io/@zooneon/OS-Process-State
- PCB : https://velog.io/@nnnyeong/OS-Context-Switching-PCB-Process-Control-Block#pcb-process-control-block
- 컨텍스트 스위칭 : https://velog.io/@nnnyeong/OS-Context-Switching-PCB-Process-Control-Block , https://hello-judy-world.tistory.com/191
- 스레드 : [https://velog.io/@aeong98/운영체제OS-프로세스와-스레드](https://velog.io/@aeong98/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EC%99%80-%EC%8A%A4%EB%A0%88%EB%93%9C), https://olivejua-develop.tistory.com/68
- 멀티스레드 장단점 : [https://velog.io/@hkh1213/멀티스레딩의-장점-단점](https://velog.io/@hkh1213/%EB%A9%80%ED%8B%B0%EC%8A%A4%EB%A0%88%EB%94%A9%EC%9D%98-%EC%9E%A5%EC%A0%90-%EB%8B%A8%EC%A0%90)
- 멀티스레드, 멀티프로세스 : [https://inpa.tistory.com/entry/👩‍💻-multi-process-multi-thread](https://inpa.tistory.com/entry/%F0%9F%91%A9%E2%80%8D%F0%9F%92%BB-multi-process-multi-thread)
- 인터럽트 : [https://velog.io/@hyun0310woo/7.-운영체제-인터럽트에-대해서](https://velog.io/@hyun0310woo/7.-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8%EC%97%90-%EB%8C%80%ED%95%B4%EC%84%9C)[https://velog.io/@narangke3/인터럽트](https://velog.io/@narangke3/%EC%9D%B8%ED%84%B0%EB%9F%BD%ED%8A%B8)
- 이중 모드 : [https://velog.io/@ongddree/운영체제-이중-동작-모드OS-dual-mode-operation](https://velog.io/@ongddree/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-%EC%9D%B4%EC%A4%91-%EB%8F%99%EC%9E%91-%EB%AA%A8%EB%93%9COS-dual-mode-operation), [https://velog.io/@codemcd/운영체제OS-3.-이중모드와-보호](https://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-3.-%EC%9D%B4%EC%A4%91%EB%AA%A8%EB%93%9C%EC%99%80-%EB%B3%B4%ED%98%B8), https://dong-co.tistory.com/47
- 멀티프로세스 정보 공유 : [https://velog.io/@ohju96/Multi-Process-환경에서-Process간-데이터-주고-받는-방법](https://velog.io/@ohju96/Multi-Process-%ED%99%98%EA%B2%BD%EC%97%90%EC%84%9C-Process%EA%B0%84-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A3%BC%EA%B3%A0-%EB%B0%9B%EB%8A%94-%EB%B0%A9%EB%B2%95)

## 질문 정리
### 커널이 무엇인가요?

**`'커널'`**은 **컴퓨터 자원을 관리하는 운영체제의 핵심 부분**이다.

**커널**은 **컴퓨터의 물리적(하드웨어) 자원과 추상화 자원을 관리**하기 위해 **시스템의 다른 모든 부분을 위한 기본적인 서비스를 제공**하고, **하드웨어를 관리**하며, **시스템 자원을 나눠준다.** 추상화는 물리적으로 하나 뿐인 하드웨어를 여러 사용자들이 번갈아 사용하게 중재함으로서 한 개의 하드웨어가 여러개인 것처럼 보여지게 한다. 이를 위해 **커널은 하나의 하드웨어 자원을 여러 사용자들을 위한 복수 개의 추상화된 객체로 관리**한다.

### 커널은 무슨 일을 하나요?

- **태스크(task)관리자**: CPU를 task라는 추상적인 자원으로써 제공
- **메모리 관리자**: 메모리를 segment나 page로 제공
- **파일시스템**: 디스크를 파일로 제공
- **네트워크 관리자**: 네트워크 장치를 소켓으로 제공
- **디바이스 드라이버 관리자**: 각종 장치를 디바이스 드라이버를 통해 일관되게 접근하도록 함

커널의 구성요소, 즉 관리자들이 존재하는 공간이 Kernel Space이다. Kernel Space 위에 사용자로 여겨지는 태스크(process)들이 존재하는 User Space가 있다. (프로그램 파일이 결국 task가 된다.)

Kernel Space와 User Space 사이에 System Call Interface가 있다. User Space의 task들이 커널이 관리하는 자원에 접근해야 할 필요가 있으면 System Call Interface를 통해 Kernel Space의 자원 관리자에게 요청이 전달된다. 그리고 이 커널의 각 자원 관리자는 사용자 요청에 맞게 알맞는 하드웨어에 사용자 명령을 전달하고 작업을 수행한다.

정리하자면, **'커널'은 사용자가 system call을 통해 컴퓨터 자원을 사용할 수 있게 해주는 자원관리자라고 볼 수 있다.**

### 유저 영역과 커널 영역에 대해 설명해 주세요.

### 유저 영역(User land)과 커널 영역(Kernel land)의 차이점

운영체제는 컴퓨터의 메모리를 관리한다. 컴퓨터를 안전하게 관리하기 위해서 유저 영역과 커널 영역으로 나누어 관리를 한다.

- **유저 영역(user land)**: 프로그램이 동작하기 위해 사용되는 메모리 공간(stack, heap, bss, data, text 영역)
- **커널 영역(kernel land)**: 운영체제를 실행시키기 위해 필요한 메모리 공간

명령어 수행 과정에서 CPU는 항상 메모리에 이번에 수행해야 할 instruction의 주소를 건네준 후 instruction과 관련된 데이터나 코드를 받아서 실행한다. 이 과정에서 지금 현재 상태가 유저 모드인지 커널 모드인지가 중요하다.

커널 모드의 경우, CPU는 어떠한 영역의 메모리라도 접근하고 모든 instruction을 실행시킬 수 있다. 한 마디로 모든 영역의 접근이 허용된다는 의미다. 하지만 유저 모드의 경우는 오직 자신의 메모리 영역에만 접근할 수 있다.

### 유저 영역과 커널 영역을 나눈 이유는 무엇일까요?

커널에서 중요한 자원, 즉 **운영체제를 실행시키기 위한 자원을 관리하기 때문에 일반 사용자가 그 중요한 자원에 접근하지 못하도록 하기 위함이다.**

### 시스템 콜은 무엇이고, 종류에 대해서 설명해 주세요.

시스템 호출(system call)은 운영 체제의 커널이 제공하는 서비스에 대해, 응용 프로그램의 요청에 따라 커널에 접근하기 위한 인터페이스이다.

사용자 프로그램이 디스크 파일을 접근하거나 화면에 결과를 출력하는 등의 작업이 필요한 경우, 즉 사용자 프로그램이 특권 명령의 수행을 필요로 하는 경우, 운영체제에게 특권 명령의 대행을 요청하는 것이 시스템 콜이다.

- 통상적으로 시스템 콜은 여러 종류의 기능으로 나누어진다.
- 각 시스템 콜에는 번호가 할당되고 시스템 콜 인터페이스는 **시스템 콜 번호와 시스템 콜 핸들러 함수 주소로 구성되는 시스템 콜 테이블**을 유지한다.
- 운영체제는 자신의 커널 영역에서 해당 인덱스가 가리키는 주소에 저장되어 있는 루틴을 수행한다.
- 작업이 완료되면 CPU에게 인터럽트를 발생시켜 수행이 완료 되었음을 알린다.

### 프로세스 컨트롤

- 프로세스 생성 및 종료
- 메모리에 로드, 실행
- 프로세스 속성 값 확인, 지정
- wait 이벤트, signal 이벤트
- 메모리 할당
- 예) fork, wait, exec 등

### 파일 매니지먼트

- 파일 생성, 파일 삭제
- 열기, 닫기
- 읽기, 쓰기, Reposition
- 파일 속성 값 확인, 지정
- 예) open, read, write, close 등

### 디바이스 매니지먼트

- 디바이스 요청 및 해제
- 읽기, 쓰기, Reposition
- 디바이스 속성 확인, 지정
- 비 물리적인 디바이스 해제 및 장착

### 정보 관리

- 시간 확인, 시간 지정
- 시스템 데이터 확인, 지정
- 프로세스, 파일, 디바이스 속성 가져오기
- 프로세스, 파일, 디바이스 속성 설정하기

### 통신

- 커뮤니케이션 연결 생성 및 삭제
- 메시지 송신, 수신
- 상태 정보 전달
- remote 디바이스 해제 및 장착

### 보안

- 파일 권한 변경 (chmod)
- 파일 소유자 변경 (chown)

### 시스템 콜은 왜 필요한가요?

우리가 일반적으로 사용하는 프로그램은 '응용 프로그램' 이다. 유저레벨의 프로그램은 유저레벨의 함수들 만으로는 많은 기능을 구현하기 힘들기 때문에, **커널(kernel)** 의 도움을 반드시 받아야 한다. 이러한 작업은 응용프로그램으로 대표되는 유저 프로세스(User Process)에서 유저모드에서는 수행할 수 없다. **반드시 kernel에 관련된 것은 커널모드로 전환한 후에야**, 해당 작업을 수행할 권한이 생긴다.

> 그렇다면 권한은 왜 필요한 것일까?
>
>
> 그 이유는 만약 권한이 없을 때, 해커가 피해를 입히기 위해 악의적으로 시스템 콜을 사용하는 경우나 초보 사용자가 하드웨어 명령어를 잘 몰라서 아무렇게 함수를 호출했을 경우에 시스템 전체를 망가뜨릴 수도 있기 때문이다. 따라서 이러한 명령어들은 특별하게 **커널 모드**에서만 실행할 수 있도록 설계되었고, 만약 유저 모드에서 시스템 콜을 호출할 경우에는 운영체제에서 불법적인 접근이라 여기고 trap을 발생시킨다.
>

### 프로세스의 구성요소와 메모리 구조에 대해 설명해 주세요.

- 프로그램 코드 및 데이터
- PCB
1. **코드(Code) 영역**
    - 프로그램 코드 자체
    - 주기억장치에 CPU가 해석할 수 있는 Binary Code 상태로 올라가게 되는데 이 영역을 뜻한다.
2. **데이터(Data) 영역**
    - 프로그램의 전역 변수(Global Variable)나 정적 변수(Static Variable)의 할당
3. **스택(Stack) 영역**
    - 지역 변수(Local Variable) 할당과 함수 호출 시 전달되는 인수(Argument) 값
4. **힙(Heap) 영역**
    - 동적 할당

### PCB의 구성요소에 대해 설명해 주세요.

### 포인터

- 프로세스의 현재 위치를 저장하는 포인터 정보

### 프로세스 상태

- 프로세스의 상태 (생성, 준비, 실행, 대기, 종료) 에 대한 정보를 저장

### 프로세스 식별자

- 모든 프로세스에는 각 프로세스를 식별하는 고유한 ID, PID 가 할당

### 프로그램 계수기(프로그램 카운터)

- 프로세스가 실행해야 하는 다음 명령어의 주소

### 레지스터

- 누산기, 베이스, 레지스터 및 범용 레지스터를 포함하는 CPU 레지스터에 있는 정보

### 메모리 제한

- 운영 체제에서 사용하는 메모리 관리 시스템에 대한 정보가 포함
- 페이지 테이블, 세그먼트 테이블 등이 포함될 수 있음

### 프로세스의 한계는 무엇인가요?

과거에는 프로그램을 실행할 때 프로세스 하나만을 사용해서 이용했었다. 하지만 기술이 발전됨에 따라 프로그램이 복잡해지고 다채로워짐으로써 프로세스 작업 하나만을 사용해서 프로그램을 실행하기에는 한계가 있었다.

오늘날 컴퓨터는 파일을 다운 받으며 다른 일을 하는 멀티 작업은 너무 당연한 기능이라고 생각할지 모르겠지만, 과거에는 파일을 다운받으면 실행 시작부터 실행 끝까지 프로세스 하나만을 사용하기 때문에 다운이 완료될때까지 하루종일 기다려야 했다.

그렇다고 동일한 프로그램을 여러 개의 프로세스로 만들게 되면, 그만큼 메모리를 차지하고 CPU에서 할당받는 자원이 중복되게 될 것이다. 스레드(Thread)는 이러한 프로세스 특성의 한계를 해결하기 위해 탄생 하였다.

### 프로세스의 상태에 대해 설명해 주세요.

## 📙 Two-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F38db7a4a-ce51-483c-a20d-badf006ecf45%2Fimage.png

가장 간단한 모델이다.

two-state 모델에는 Not Running과 Running 상태 두 가지로 나뉜다.

- Not Running : 실행 대기 중인 상태
- Running : 현재 실행 중인 상태

### State Transitions

새 프로세스가 생성되면 OS는 프로세스의 PCB(Program Control Block)를 생성하고 not running 상태로 초기화 시킨다.

not running 상태인 프로세스들은 Queue에서 대기하게 되는데, Queue에는 각 프로세스의 PCB 주소를 가르키는 포인터를 갖고 있다.

만약 현재 실행중인 running 상태의 프로세스에서 Interrupt가 발생하면 OS는 해당 프로세스를 not running 상태로 옮긴다.

그러면 dispatcher가 Queue에서 대기 중인 프로세스들 중 하나를 골라 running 상태로 옮긴다.

## 📕 Five-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F861fd89e-17a6-433e-88fe-832a606e96d8%2Fimage.png

five-state 모델은 다섯가지 상태로 나뉜다.

- New : 프로세스가 만들어진 상태이다. 프로세스가 생성되면 바로 Ready 단계로 가면 되는거 아닌가? 라고 생각할 수 있다. 하지만 프로세스가 만들어지면 메모리도 할당해야하고 프로세스의 정보를 담고 있는 PCB와 프로세스가 실행되면서 사용할 스택 메모리도 할당하고 초기화해줘야 한다. 그렇기 때문에 프로세스 생성에는 시간이 걸리고 New 상태에 어느 정도 머물러야 한다.
- Ready : 실행을 하기 위해 기다리는 상태이다. 언제든지 실행할 준비가 되어있고, CPU를 할당해주면 바로 실행할 수 있는 단계이다.
- Running : 프로세스가 CPU를 차지하고 실행하고 있는 상태이다.
- Blocked : CPU를 할당해주어도 실행할 수 없는 상태이다.(I/O request, 다른 프로세스가 끝날 때까지 대기 등등)
- Exit : 프로세스가 끝나게 되면 프로세스가 할당 받았던 자원들을 반납해야한다. 따라서 Exit 상태에서도 처리 시간이 걸린다.

### State Transitions

**New → Ready**

New 상태에서 Ready 상태로 자연스럽게 넘어가는 것이 아니라 OS가 Ready 단계로 허락(Admit)할 때 넘어갈 수 있다.

OS의 허락을 맡는 이유는 메모리 자원 문제와 CPU 문제가 있다.

메모리의 공간은 한정적이기 때문에 메모리에 올릴 수 있는 프로그램도 한정적이다. 그렇기 때문에 프로그램을 메모리에 올리기 전에 올려도 되는지 OS의 허락이 필요하다.

두 번째 이유로 CPU가 있다. CPU는 프로그램을 Time Sharing을 통해 동시에 진행하는 것처럼 보이게 한다. 하지만 프로그램이 많아지면 각 프로그램의 대기 시간이 길어지게 되고 이는 버벅이는 것처럼 보이는 문제가 될 수 있다.

**Ready → Running**

Dispatcher가 대기하고 있는 프로그램 중 적절한 프로그램을 골라 Running 상태로 옮긴다.

**Running → Exit**

OS는 프로그램이 종료하게 되면 Exit 상태로 옮긴다.

**Running → Ready**

CPU는 Time Sharing을 통해 프로세스들을 실행시키므로 프로그램이 길면 timeout이 걸려 Ready 상태로 돌아가게 된다.

**Running → Blocked**

프로그램 실행 중 I/O request가 발생하거나 OS에 어떤 작업을 요청하면 Blocked 상태로 변경한다.

**Blocked → Ready**

기다리던 이벤트가 발생하면 바로 Running 상태로 가는 것이 아닌 Ready 상태로 간다.

## 📗 Seven-State Process Model

!https://velog.velcdn.com/images%2Fzooneon%2Fpost%2F214b2594-8ed1-47f2-8ee6-40ff4c963473%2Fimage.png

Five state process model with two suspended states

> Suspend란?
>
>
> Suspend는 메모리에서 꺼내서 하드디스크로 옮기는 것이다.
>
> Queue에 있는 프로그램의 포인터를 이용하여 옮긴다.
>

five-state 모델에서 Ready/Suspend 상태와 Blocked/Suspend 상태가 추가된 모델이다.

- Ready/Suspend : I/O 작업이나 요청한 작업이 끝났지만 메모리에 자리가 없어 여전히 하드디스크에 있는 상태이다.
- Blocked/Suspend : 요청한 작업이 끝나지 않았고, 메모리에 있던 프로세스들이 Swaping으로 인해 하드디스크로 내려간 상태이다.

> Swaping이란?
>
>
> 메모리의 크기는 한정적이기 때문에 들어올 수 있는 프로그램의 수는 정해져 있다.
>
> 올라온 프로세스들이 모두 block이 되면 CPU가 하는 일이 없어지기 때문에 하드디스크에서 대기 중인 프로세스들을 메모리에 올리고 기존의 메모리에 있던 프로세스들은 하드디스크로 내린다.
>
> 이 작업을 Swaping이라고 한다.
>

### State Transitions

**Blocked → Blocked/Suspend**

메모리에 올라와 있는 프로세스들이 모두 요청한 작업을 하느라 block 상태이고, 하드디스크에 Swapped 되었던 프로세스들을 메모리에 올려야 한다. 그러기 위해 메모리에 있던 프로세스들을 하드디스크의 Swapped Area로 옮긴다.

**Blocked/Suspend → Blocked**

요청한 작업이 다 끝나지 않았지만 메모리에 공간이 충분히 있을 경우 다시 메모리로 올라갈 수 있다.

**Blocked/Suspend → Ready/Suspend**

요청한 작업이 다 끝났지만 메모리에 공간이 없는 경우 Ready/Suspend 상태로 옮긴다.

**Ready/Suspend → Ready**

Ready/Suspend 상태에서 대기하던 중 메모리에 공간이 생겨 다시 Ready 상태로 변경한다.

**Ready → Ready/Suspend**

여러 suspend 이유로 Ready에서 Ready/Suspend로 옮겨질 수 있다. 예를 들어 프로세스의 우선순위 때문에 메모리에 공간을 만들어야할 경우 Ready/Suspend 상태로 옮겨진다.

**New → Ready/Suspend**

만약 메모리가 가득 차 있는 경우라면 OS는 New 상태에서 Ready/Suspend 상태로 Admit 한다.

### 컨텍스트 스위칭이란 무엇인가요?

CPU가 현재 작업중인 프로세스에서 다른 프로세스로 넘어갈 때, 이전의 프로세스 정보를 PCB에 저장하고 새롭게 실행할 프로세스의 정보를 PCB에서 읽어와 레지스터에 적재하는 과정을 말한다.

## Context

- 프로세스의 데이터
- CPU 레지스터 값

CPU 가 프로세스를 실행시키기 위해 필요한 정보들을 **Context** 라 한다.

프로세스가 메모리에 올라가 실행 될 때 CPU 내에 존재하는 레지스터들이 현재 실행중인 프로세스 관련 데이터로 채워지게 되고 실행중인 프로세스가 변경되면 CPU 내의 레지스터 값들이 변경된다.

### 컨텍스트 스위칭 과정에 대해 설명해 주세요.

- 요청 발생
    - 인터럽트나 트렙에 의해서 컨텍스트를 바꿔야 한다는 요청이 들어옴
- PCB 에 프로세스 정보 저장
    - 기존에 실행중이던 프로세스 `P0` 와 관련된 정보들을 PCB 에 저장함
- CPU 새롭게 할당
    - 운영체제는 새롭게 실행할 프로세스 `P1` 에 대한 정보를 해당 PCB 에서 가져와 CPU 레지스터에 적재함

### 컨텍스트 스위칭은 어떤 경우에 일어나나요?

### 멀티 태스킹

실행 가능한 여러개의 프로세스들이 운영체제의 스케쥴러에 의해, 우선순위에 따라 조금씩 번갈아가면서 수행된다. CPU를 할당 받는 프로세스가 변경될 때 마다 컨텍스트 스위칭이 일어난다.

### 인터럽트 핸들링

컴퓨터 시스템에서 예외 상황이 발생했을 때 이를 CPU 에게 알려 실행중이던 프로세스 정보를 저장하고 발생한 예외 상황을 처리하기 위한 컨텍스트 스위칭이 일어난다.

### 사용자모드 커널모드 전환 (User and Kernel mode Switching)

- context switching 이 필수는 아니지만 운영체제에 따라 발생 가능하다.

### 컨텍스트 스위칭 오버헤드는 무엇 때문에 일어나나요?

컨텍스트 스위칭 오버헤드는 대표적으로 다음과 같은 행위에 의해서 발생된다.

1. PCB 저장 및 복원 비용
2. CPU 캐시 메모리 무효화에 따른 비용
3. 프로세스 스케줄링 비용

### 프로세스 컨텍스트 스위칭 & 스레드 컨텍스트 스위칭을 비교해 주세요.

**[ 프로세스 컨텍스트 스위칭 (Process Context Switching) / 스레드 컨텍스트 스위칭 (Thread Context Switching) ]**

**1) 공통점**

- 커널 모드에서 실행
- CPU의 레지스터 상태를 교체

**2) 차이점**

- 프로세스 컨텍스트 스위칭
    - 서로 다른 프로세스에 속한 스레드 간의 컨텍스트 스위칭 발생
    - 가상(virtual) 메모리 주소 관련 처리를 추가로 수행 / MMU, TLB 다시 세팅해야 함
- 스레드 컨텍스트 스위칭
    - 같은 프로세스에 속한 스레드 간의 컨텍스트 스위칭 발생

### **✔️ Point2 : 스레드 컨텍스트 스위칭이 더 빠른 이유**

메모리 주소 관련 처리를 하지 않기 때문이다.

> - 현재 실행 중인 프로세스 혹은 스레드의 context 백업 (가령, CPU 레지스터 값들, 어디까지 실행됐는지 등)
>

프로세스 컨텍스트 스위칭은 위 4가지 모두 수행하지만, 스레드 컨텍스트 스위칭은 첫번 째만 수행하면 된다.

💁‍♀️ **서로 다른 프로세스** : 서로 다른 메모리 주소 공간(memory address space)

💁‍♂️ **같은 프로세스 내 스레드** : 소속된 프로세스의 메모리 주소 공간 공유

그래서 프로세스가 바뀔 때  새로 실행되는 프로세스가 기존에 실행되는 프로세스의 메모리 주소 공간에 침범하면 안 되기 때문에 추가적인 작업이 필요하다.

그래서 **프로세스 컨텍스트 스위칭 작업이 더 오래 걸린다.**

### 프로세스 컨텍스트 스위칭 vs 스레드 컨텍스트 스위칭

프로세스 컨텍스트 스위칭과 스레드 컨텍스트 스위칭은 모두 멀티태스킹 환경에서 여러 프로세스 또는 스레드를 동시에 실행하기 위한 기술이다. 그러나 두 기술은 몇 가지 차이점이 있다.

1. TCB가 PCB보다 가볍다

결론부터 말하자면, 스레드 컨텍스트 스위칭이 프로세스 컨텍스트 스위칭보다 더 빠르다.

위에서 프로세스와 스레드의 메모리 섹션에서 다뤘듯이, 프로세스 내의 스레드들은 text, data, heap 영역 메모리를 공유하기 때문에 TCB에는 stack 및 간단한 register 포인터 정보만을 저장하기 때문에 PCB보다 TCB가 가벼워 더 빨리 읽고 쓸수 있다.

!https://blog.kakaocdn.net/dn/bX1zDN/btr7Pj57YmU/dOnxKJqOLBwdYd4SYlsiH0/img.png

1. 캐시 메모리 초기화 여부

CPU 캐쉬 메모리는 CPU와 메인 메모리 사이에 위치하며 CPU에서 한번 이상 읽어들인 메모리의 데이터를 저장하고 있다가, CPU가 다시 그 메모리에 저장된 데이터를 요구할 때, 메인 메모리를 통하지 않고 곧바로 데이터를 전달해 주는 용도이다. 그런데 프로세스 컨텍스트 스위칭이 일어날 경우, 다른 프로세스의 실행으로 인해 CPU가 새로운 명령어와 데이터를 로드해야 하기 때문에 CPU 캐시 메모리를 초기화 하여야 한다. 이것이 프로세스 컨텍스트 스위칭에 부담이 되는 요소이다.

스레드 컨텍스트 스위칭일 경우, 프로세스 내 스레드 간에 스택과 레지스터 값 등 일부 컨텍스트 정보만 변경되므로 CPU 캐시 메모리는 초기화되지 않는다. 다만 스레드가 다른 CPU 코어에서 실행될 때는 해당 코어의 캐시 메모리에 스레드 컨텍스트 정보가 로드되어야 하므로 초기화될 수 있다.

1. 자원 동기화 문제

스레드 컨텍스트 스위칭이 발생해 다른 스레드가 heap 영역의 공유 데이터에 접근할때, 이전 스레드가 이미 공유 자원을 사용하고 있는 경우 동기화 문제가 발생할 수 있다. 예를 들어, 두 개의 스레드가 동시에 하나의 변수를 수정하려고 할 때, 스레드 컨텍스트 스위칭이 발생하면 변수의 값을 잘못된 값으로 업데이트 할 수 있는 것이다. 이것을 스레드 간에 경쟁 조건 (race condition)이라고 한다.

프로세스는 기본적으로 독립된 공간이지만, IPC와 같은 공유 자원을 사용하는 경우에 똑같이 경쟁 조건이 발생 할 수가 있다. 예를 들어, 여러 개의 프로세스가 동시에 파일 시스템에 접근하여 파일을 수정하려고 할 때, 컨텍스트 스위칭이 발생할 때 다른 프로세스가 그 파일에 접근할 수 있기 때문에 파일 내용이 손상될 수 있다.따라서 이들을 해결하기 위해선 각 상황에 적절한 공유 자원에 대한 동기화 메커니즘이 필요해진다.

### 스레드란 무엇인가요?

프로세스가 할당받은 자원을 이용하는 **실행 흐름**의 단위이다. 스레드는 운영체제의 스케줄러에 의해 독립적으로 관리될 수 있는 프로그래밍된 명령어의 가장 작은 시퀀스이다. 하나의 프로세스는 하나 이상의 스레드를 갖고 있다.

### 스레드의 장단점에 대해 설명해 주세요.

장점

- 컨텍스트 스위칭 시 스레드 공유 영역(Code~Heap)은 올리고 내릴 필요가 없다.
- Data와 Heap 영역을 스레드끼리 공유할 수 있어서 중복된 데이터만큼 자원(메모리)을 아낄 수 있다.
- 다중 CPU 구조에서는 각각의 스레드가 다른 프로세서에서 병렬로 수행될 수 있으므로 병렬성이 증가한다.

단점

- 둘 이상의 쓰레드가 하나의 변수에 접근하려고 할 때 문제가 발생할 수 있다. (임계영역)
- 쓰레드 하나가 프로세스 내의 자원을 망친다면 프로세스 종료될 수 있다. 프로세스가 종료되면 그 안에 실행되고 있던 스레드는 모두 강제종료된다.

### 스레드의 상태에 대해 설명해 주세요.

- NEW : 스레드가 생성되고 아직 호출되지 않은 상태
- RUNNABLE : 스레드가 실행되기 위해 기다리는 상태. CPU를 할당받을 수 있는 상태이며, 언제든지 실행될 준비가 되어있다.
- BLOCKED : 스레드가 특정 이벤트(입출력 요청 등)가 발생하여 대기하는 상태
  CPU를 할당받지 못하며, 이벤트가 발생하여 다시 RUNNABLE 상태로 전환될 때까지 대기한다.
- TERMINATED : 스레드가 실행을 완료하고 종료된 상태. 더 이상 실행될 수 없으며, 메모리에서 제거된다.

### 스레드의 메모리 구조에 대해 설명해 주세요.

Code 영역부터 Heap 영역까지는 모든 스레드가 공유하고 Stack 영역만 각각 사용한다.

### 동시성과 병렬성에 대해 설명해 주세요.

동시성은 하나의 코어에서 두개의 쓰레드를 매우 빠른 속도로 마치 동시에 실행하는 것처럼 번갈아가면서 처리한다

병렬성은 두개의 코어에서 각각 하나의 쓰레드를 맡아 진짜 동시에 처리하는 것을 말한다.

### 멀티 프로세스와 멀티 스레드에 대해 설명해 주시고, 장단점에 대해 말씀해 주세요.

### 멀티 프로세스

### 멀티 프로세스의 장점

1. 프로그램 안전성

멀티 프로세스는 각 프로세스가 독립적인 메모리 공간을 가지므로, 한 프로세스가 비정상적으로 종료되어도 다른 프로세스에 영향을 주지 않는다. 그래서 프로그램 전체의 안전성을 확보할 수 있다는 장점이 있다.

예를 들자면 크롬 브라우저에서 여러개의 탭을 띄우고 여러곳의 웹사이트를 방문해 서비스를 이용한다고 하자. 이때 어느 한 탭의 웹사이트에서 무언가 잘못되어 먹통이 되었다.

아주 심각한 오류가 아닌 이상, 당장 그 브라우저 탭의 웹사이트는 이용을 못하겠지만, 다른 탭은 별 문제없이 이용이 가능할 것이다. 이러한 이유는 자식 프로세스가 여러개 생성되어 메모리에 별도로 관리되기 때문이다.

1. 프로그램 병렬성

멀티 프로세스와 여러개의 CPU 코어를 활용하여 둘의 시너지를 합쳐, 다중 CPU 시스템에서 각 프로세스를 병렬적으로 실행하여 성능을 향상 시킬 수 있다. 예를 들어 이미지 처리나 비디오 인코딩과 같은 작업을 여러 개의 코어나 CPU에 분산시켜 빠르게 처리할 수 있다.

다만, 이 부분은 멀티 프로세스 만의 장점이라기 보단, 멀티 프로세스와 멀티 스레드 둘의 장점이 옳다. 그리고 멀티 스레드로 구성하는 것이 멀티 프로세스로 구성하는 것보다 훨씬 효율적이고 빠르기 때문에, 멀티 프로세스로 성능을 올리는 행위는 거의 없다고 보면 된다. 이에 대해선 뒤의 멀티 스레드 파트에서 다시 다룬다.

1. 시스템 확장성

멀티 프로세스는 각 프로세스가 독립적이므로, 새로운 기능이나 모듈을 추가하거나 수정할때 다른 프로세스에 영향을 주지 않는다. 그래서 시스템의 규모를 쉽게 확장할 수 있다.

이 부분에 대해서는 컴퓨터의 소프트웨어로 예시를 드는 것보다 네트워크의 서버(server)로 드는 것이 적절하기 때문에 잠시 분산 서버에 대해서 말해보겠다. 대규모 웹 서비스에서는 수많은 요청을 동시에 처리하기 위해 여러대의 서버를 두고 로드 밸런서(Load Balancer)와 같은 장비를 사용하여 클라이언트 요청 트래픽을 분산 시킨다. 이때 여러대의 서버는 컴퓨터를 여러개를 말하는 것일 수도 있고, 하나의 성능 좋은 컴퓨터에 여러개의 서버 프로세스를 두는 것을 말하기도 한다. 멀티 프로세스의 상황은 후자이다.

서버 프로그래밍을 해본 백엔드 개발자분들은 서버 클러스터(cluster)를 구성해본 적이 있을 것이다. 하나의 컴퓨터에 여러개의 서버 프로세스를 띄움으로써 요청을 분산시키는 것이다. Node.js 진영에선 대표적으로PM2Visit Website 가 있다.이렇게 멀티 프로세스를 사용하여 여러 대의 서버에 요청을 분산시켜 처리함으로써, 시스템의 규모를 쉽게 확장할 수 있으며, 부가로 서버의 장애나 다운타임을 최소화할 수 있게 되는 것이다.

### 멀티 프로세스의 단점

1. Context Switching Overhead

   !https://blog.kakaocdn.net/dn/c8hWqD/btr6rw5WrBY/6Zun2QryWJBoiyh4FGrqCk/img.png


멀티 태스킹(multi tasking)Visit Website을 구성하는데 핵심 기술인 컨텍스트 스위칭(context switching) 과정에서 성능 저하가 올 수 있다. 특히나 프로세스를 컨텍스트 스위칭 하면, CPU는 다음 프로세스의 정보를 불러오기 위해 메모리를 검색하고, CPU 캐시 메모리를 초기화하며, 프로세스 상태를 저장하고, 불러올 데이터를 준비해야 하기 때문에, 이로 인한 빈번한 Context Switching 작업으로 인해 비용 오버헤드가 발생할 수 있게 된다.

반면 스레드를 컨텍스트 스위칭하면 프로세스 스위칭 보다 가벼워 훨씬 빠르고 좋다.프로세스 1에서 2로 스위칭할때 아주 약간의 빈 시간(오버헤드)가 발생한다.

따라서, 멀티 프로세스 환경에서는 Context Switching Overhead를 최소화하는 방법이 중요하다. 이를 위해서 프로세스 수를 적정하게 유지하거나, I/O 바운드 작업이 많은 프로세스와 CPU 바운드 작업이 많은 프로세스를 분리하여 관리하고, CPU 캐시를 효율적으로 활용하는 등의 방법을 고려해 봐야 한다.

1. 자원 공유 비효율성

   !https://blog.kakaocdn.net/dn/wHlQM/btr53ErRepe/bojoHmQqek8FjkKLY25Zo0/img.png


멀티 프로세스는 각 프로세스가 독립적인 메모리 공간을 가지므로, 결과적으로 메모리 사용량이 증가하게 된다.만일 각 프로세스간에 자원 공유가 필요할 경우 프로세스 사이의 어렵고 복잡한 통신 기법인 IPC(Inter-Process Commnuication)을 사용하여야 한다.
IPC란 운영체제 상에서 실행 중인 프로세스 간에 정보를 주고받는 메커니즘을 말한다. 이를 위해 파이프, 소켓, 메세지 큐 등 다양한 방법이 사용된다. 그런데 IPC 자체로 오버헤드가 발생한다. 예를 들어, 파이프나 소켓과 같은 IPC 기법은 데이터를 복사하거나 버퍼링하는 과정에서 성능 저하가 발생할 수 있기 때문이다. 또한 코드의 복잡도를 증가시킨다.

### 멀티 스레드

### 멀티 스레드의 장점

윈도우, 리눅스 등 많은 운영체제들이 멀티 프로세싱을 지원하고 있지만 멀티 스레딩을 기본으로 하고 있다.왜 멀티 프로세스 보다 멀티 스레드로 프로그램을 돌리는 것이 유리한지 그 이유에 대해 알아보자. (이는 스레드 자체의 장점이기도 하다)

1. 스레드는 프로세스보다 가벼움

일단 스레드는 프로세스 보다 용량이 가볍다. 그도 그럴게 스레드는 프로세스 내에서 생성되기 때문에 스레드의 실행 환경을 설정하는 작업이 매우 간단하여 생성 및 종료가 빠르다. 또한 스레드는 프로세스와 달리, 코드, 데이터, 스택 영역을 제외한 나머지 자원을 서로 공유하기 때문에 기본적으로 내장되어 있는 데이터 용량이 프로세스보다 당연히 작다. 그래서 스레드를 생성하고 제거할 때, 프로세스 내부의 자원만을 관리하면 되기 때문에 프로세스 생성, 제거 보다 훨씬 빠른 것이다.

1. 자원의 효율성

   !https://blog.kakaocdn.net/dn/bilJ94/btr6rxcJ12e/yGcKc7yuB3nDWXWso0l3T0/img.png


멀티 스레드는 하나의 프로세스 내에서 여러 개의 스레드를 생성되기 때문에, heap 영역과 같은 공유 메모리에 대해 스레드 간에 자원을 공유가 가능하다. 이를 통해, 프로세스 간 통신 (IPC)을 사용하지 않고도 데이터를 공유할 수 있기 때문에, 자원의 효율적인 활용이 가능해 시스템 자원 소모가 줄어든다.

1. Context Switching비용 감소

   !https://blog.kakaocdn.net/dn/PpwcB/btr73xQQciT/mosSUj7hHNLFKQ4s3sXPK1/img.jpg


스레드에도 컨텍스트 스위칭 오버헤드가 존재한다. 하지만 상대적으로 프로세스 컨텍스트 스위칭 오버헤드보다 훨씬 낮아 비용이 낮다는 장점이 있다. 프로세스 컨텍스트 스위칭 비용은 스위칭할 때마다 CPU 캐시에 있는 내용을 모두 초기화하고, 새로운 프로세스 정보를 CPU 캐시에 적재해야 하므로 높은 비용이 든다. 반면, 스레드 컨텍스트 스위칭 비용은 스위칭할 때 스레드 간에 공유하는 자원을 제외한 스레드 정보(stack, register)만을 교체하면 되므로 프로세스 컨텍스트 스위칭 비용보다 상대적으로 낮은 것이다.

1. 응답 시간 단축

앞의 멀티 스레드의 장점을 종합해보자면, 멀티 스레드는 스레드 간의 통신이나 자원 공유가 더욱 용이하며, 프로세스 보다 가벼워 컨텍스트 스위칭 오버헤드도 작다. 따라서 멀티 프로세스 보다 응답 시간이 빠르다.예를 들어, 웹 서버에서 클라이언트 요청을 처리하는 경우, 멀티 프로세스 방식에서는 각 요청마다 프로세스를 생성하여 처리해야 하므로, 오버헤드가 크지만, 멀티 스레드 방식에서는 여러 개의 스레드가 하나의 프로세스 내에서 요청을 처리할 수 있으므로, 오버헤드가 감소해 더욱 빠른 응답 시간을 보장할 수 있는 것이다.이러한 이유로, 멀티 프로세서 환경에서 멀티 스레드를 사용하여 작업을 처리하는 것이 멀티 프로세스를 사용하는 것보다 더 효율적이다라고 말할 수 있다.

### 멀티 스레드의 단점

1. 안정성 문제

   !https://blog.kakaocdn.net/dn/L5gYp/btr6eUGAI4R/9UC9f5ZWqb9TakHZWmCc30/img.png


멀티 프로세스 모델에서는 각 프로세스가 독립적으로 동작하므로 하나의 프로세스에서 문제가 발생해도 다른 프로세스들은 영향을 받지 않기 때문에 프로그램이 죽지 않고 계속 동작할 수 있다. 그러나 멀티 스레드 모델에서는 기본적으로 하나의 스레드에서 문제가 발생하면 다른 스레드들도 영향을 받아 전체 프로그램이 종료될 수 있다. 물론 이는 프로그래머의 역량에 따라 극복할 수 가 있다. 예를 들어 스레드에 에러가 발생할 경우 이에 대한 적절한 예외 처리를 잘 해놓는다던지, 에러 발생 시 새로운 스레드를 생성하거나 스레드 풀(Thread Pool)에서 잔여 스레드를 가져오던지 하여 프로그램 종료를 방지할 수 있다. 다만, 이때 새로운 스레드 생성이나 놀고 있는 스레드 처리에 추가 비용이 발생하게 된다.

1. 동기화로 인한 성능 저하

   !https://blog.kakaocdn.net/dn/bmehI6/btr736r6Tw6/wTH0UPpQfmgkgozqmiwte1/img.png


멀티 스레드 모델은 여러 개의 스레드가 공유 자원에 동시에 접근할 수 있기 때문에, 동기화 문제가 발생할 수 있다. 예를 들어 여러 스레드가 동시에 한 자원을 변경해 버린다면 의도되지 않은 엉뚱한 값을 읽어 서비스에 치명적인 버그가 생길수도 있다. 따라서 스레드 간 동기화(syncronized)는 데이터 접근을 제어하기 위한 필수적인 기술이다.동기화 작업은 여러 스레드들이 자원에 대한 접근을 순차적으로 통제하는 것이다. 그러면 동시 접근으로 인한 동시 수정과 같은 현상은 일어나지 않게 된다. 그러나 동기화 작업은 여러 스레드 접근을 제한하는 것이기 때문에병목 현상이 일어나 성능이 저하될 가능성이 높다는 단점이 있다.

이를 해결하기 위해 임계 영역(Critical Section)에 대하여 뮤텍스(mutex), 또는 세마포어(Semaphore) 방식을 활용한다.

> 임계 영역(Critical Section)- 멀티 스레드 프로그래밍에서 임계 영역은 공유 자원을 접근하는 코드 영역을 말한다. 대표적으로 전역 변수나 heap 메모리 영역을 들 수 있겠다.
뮤텍스(Mutex)- 공유 자원에 대한 접근을 제어하기 위한 상호 배제 기법 중 하나로, 임계 영역에 진입하기 전에 락(lock)을 획득하고, 임계 영역을 빠져나올 때 락을 해제하여 다른 스레드들이 접근할 수 있도록 한다. 한마디로 오직 1개의 스레드만이 공유 자원에 접근할 수 있도록 제어하는 기법이다.
세마포어(Semaphore)- 세마포어는 동시에 접근 가능한 스레드의 개수를 지정할 수 있다. 세마포어 값이 1이면 뮤텍스와 동일한 역할을 하며, 값이 2 이상이면 동시에 접근 가능한 스레드의 수를 제어할 수 있다. 스레드가 임계 영역에 진입하기 전에 세마포어 값을 확인하고, 값이 허용된 범위 내에 있을 때만 락을 획득할 수 있는 형식이다. 한마디로 뮤텍스 상위 호환 이라고 보면 된다.
>
1. 데드락 (교착 상태)

   !https://blog.kakaocdn.net/dn/bgRSP9/btr6ouO1S99/B3N1ylkovSB8eUTXKAOKb1/img.png


Deadlock 이란, 다수의 프로세스나 스레드가 서로 자원을 점유하고, 다른 프로세스나 스레드가 점유한 자원을 기다리는 상황에서 발생하는 교착 상태를 말한다. 여러 개의 스레드가 서로 대기하면서 무한정 기다리게되는 무한 루프와 같은 증상이라고 보면된다.

예를들어, 스레드 1 은 자원 A을 점유하고 있는 상태에서 자원 B가 필요한 상황이다. 그리고 스레드 2 는 자원 B를 점유하고 있는 상태에서 자원 A이 필요한 상황이다. 하지만 스레드 1은 자원 B가 필요한 상황에서 자원 A을 빌려줄 수 있는 상황이 아니고, 스레드 2또한 자원 A이 필요한 상태에서 자원 B를 빌려줄 수 없는 상황인 것이다.이처럼 다수의 쓰레드가 같은 lock을 동시에, 다른 명령에 의해 획득하려 할 때 서로 절대 불가능한 일을 계속적으로 기다리는 상황을 이야기 한다.

이러한 현상은 스레드의 특징인 공유 자원에 대한 동시 엑세스로 인한 문제로, 이를 방지하기 위한 상호배제(Mutual Exclusion), 점유와 대기(Hold and Wait), 비선점(No Preemption), 순환 대기(Circular Wait) 등의 알고리즘을 통해 극복해야 한다.

다만, 데드락은 멀티 스레드만의 단점이라기 보다는 멀티 프로세스와 스레드 모델의 공통된 문제점이라고 말하는 것이 옳다. 왜냐하면 프로세스 끼리는 기본적으로 독립적인 메모리 공간이지만 IPC를 통해 공유 자원을 사용할 수 있기 때문에 멀티 스레드와 똑같이 교착 상태에 빠질 수 있기 때문이다.

1. 그래도 Context Switching Overhead

앞서 멀티 프로세스보다 멀티 스레드의 컨텍스트 스위칭 오버헤드가 작아 성능에 유리하다라고 설명했었지만, 그래도 컨텍스트 스위칭 오버헤드 비용 자체를 무시할수는 없다.

특히나 스레드 수가 많으면 많을 수록 그만큼 컨텍스트 스위칭이 많이 발생되게 되고 당연히 이는 성능 저하로 이어진다.이 부분은 '스레드를 많이 쓸수록 항상 성능이 좋아질까?' 라는 물음으로 던질 수 있다. 보통 사람들이 생각하기에는 스레드가 많으면 많을 수록 그만큼 동시 처리수가 늘어나 당연히 스레드가 많으면 무조건 좋다고 이야기할 것이다.

하지만 '컨텍스트 스위칭 오베허드'라는 개념을 알고 있는 개발자인 우리들은 '과연 꼭 그럴까?' 라는 의문을 던져야 한다.이 부분은 스레드를 겉핥기로만 배운 지원자를 걸러내기 위해 기술 면접에서 가끔 등장하는 고수준의 질문이기도 하다.

1. 디버깅이 어려움

   !https://blog.kakaocdn.net/dn/sxYJz/btr76ZeA0uk/UZQiQEy8Ki1jcnH5AzsmP1/img.png


멀티 스레드를 사용하면, 여러 개의 스레드가 동시에 실행되기 때문에, 각 스레드의 동작을 추적하기 어려울 수 있다. 예를들어 코드를 디버깅하는 도중에 다른 스레드가 실행되어 예기치 않은 결과가 발생할 수 있다. 또한 어떤 스레드가 언제 어떤 자원에 접근하고, 어떤 순서로 실행되는지 등을 파악하기 어려울 수 있다.따라서 스레드 간의 상호작용과 동기화 기법을 잘 이해하고, 디버깅 도구를 적극적으로 활용해야 한다.

1. 운영체제의 지원이 필요

오늘날의 윈도우, 리눅스, 맥 OS에선 모두 기본적으로 멀티 스레딩을 기본적으로 지원하도록 설계 되었으니 문제점이라기에는 약간 어폐가 있긴 하다. 하지만, 1980년대의 SunOS3와 같은 오래된 유닉스 시스템에는 스레드가 없었고 프로세스만 있는, 멀티 스레딩을 지원하지 않는 운영 체제가 있었기 때문에 멀티 스레드의 단점으로 넣어 보았다. (그만 잊어도 된다 😅)

프로세스 자원 공유는 단순히 CPU 레지스터 교체뿐만이 아니라 RAM과 CPU 사이의 캐시 메모리까지 초기화되기 때문에 자원 부담이 크다는 단점이 있다.

그래서 다중 작업이 필요한경우 스레드를 이용하는 것이 훨씬 효율적이라, 현대 컴퓨터의 운영체제에선 다중 프로세싱을 지원하고 있지만 다중 스레딩을 기본으로 하고 있다.

### 멀티 프로세스간 정보공유를 하는 방법에 대해 설명해 주세요.

### Multi Process 환경에서 Process간 데이터를 어떻게 주고 받을까?

멀티 프로세스 환경에서 프로세스간 데이터를 주고 받기 위해서 IPC(Inter Process Communication)을 제공한다. 간단하게 IPC는 파이프, 소켓, 파일, 공유 메모리 등이 있고 크게는 공유 메모리와 메시지 전달 방식으로 나뉘게 된다.

### IPC(Inter Process Communication)란?

프로세스는 독립적인 주소 공간을 가지고 있어서 다른 프로세스와 데이터를 주고 받을 수 없는데 이런 문제를 해결하기 위한 기법이다. IPC를 통해 프로세스간 통신이 가능하게 만들어준다.

크게 공유 메모리 방식과 메시지 전달 방식이 있는데 아래서 다룬다.

## 공유 메모리(Shared Memory)

공유 메모리 방식은 프로세스들이 주소 공간의 일부를 공유하고 공유된 메모리 영역에 읽기와 쓰기를 하면서 통신하는 방식이다.

메모리는 **`스택-힙-데이터-코드`**영역으로 이루어져있지만 공유 메모리를 할당 받으면 **`스택-힙-데이터-공유메모리-코드`** 이렇게 메모리 공간에 공유 메모리 공간이 추가가 된다.

### 공유 메모리 형성 과정

공유 메모리가 형성되는 과정은 아래와 같다.

1. 프로세스가 공유 메모리 할당을 커널에 요청
2. 커널이 해당 프로세스에 메모리 공간을 할당

이런 두 과정을 거쳐 공유 메모리 공간이 형성된다.

### 공유 메모리 특징

공유 메모리가 형성되면 공유 메모리에 대한 접근이 일반 메모리 접근과 똑같이 취급되어진다. 한 번 공유 메모리가 형성되면 다음엔 커널의 도움이 없어도 각 프로세스들이 메모리 영역에 접근할 수 있기 때문에 IPC 속도가 빠르다는 특징이 있다.

하지만 프로세스 내의 메모리 공간에 공유 메모리 공간이 할당되어 접근이 수월하고 속도가 빠른 대신 서로 다른 프로세스가 동시에 같은 메모리 위치에 접근하면 일관성 문제가 생기는데 이 문제에 대해서는 커널이 책임지지 않기 때문에 각 프로세스들이 공유 메모리 접근에 대한 동기화 문제를 책임져야 하는 단점이 있다.

## 메시지 전달(Message Passing)

메시지 전달은 공유 메모리와 다르게 무조건 커널을 통해 데이터를 전달한다.(send message와 receive message라는 두 가지 연산을 제공 받는다.)

한마디로 데이터를 전달함에 있어 중간에 커널이 중개 역할을 하는 것이다.

### 메시지 전달 과정

메시지 전달의 과정은 아래와 같다.

1. 프로세스 A가 프로세스 B에게 보낼 데이터를 커널에 보낸다.
2. 커널은 프로세스 A한테 온 메시지를 받고 프로세스 B한테 보내준다.

간단한 과정이다.

### 메시지 전달 특징

메시지 전달은 커널을 무조건 거쳐야 한다는 점 때문에 첫 과정을 제외한 나머지는 직접 메모리에 접근이 가능한 공유 메모리와는 달리 속도가 느리다는 단점이 있다.

하지만 커널이 관여하고 있는 만큼 동시 접근에 대한 충돌을 걱정할 필요가 없어 적은 양의 데이터를 교환하는데 효과적이고 구현이 비교적 쉽다는 장점이 있다.

대표적으로 파이프, 소켓, 메시지 큐 등의 방법이 메시지 전달 방식으로 구현된다.

### 인터럽트란 무엇이고 왜 필요한가요?

### 인터럽트란

**CPU가 특정 기능을 수행하는 도중에 급하게 다른 일을 처리하고자 할 때 사용할 수 있는 기능**

이다.

대부분의 컴퓨터는 한 개의 CPU를 사용하므로 한 순간에는 하나의 일 밖에 처리할 수 없기 때문에

**어떤 일을 처리하는 도중에 우선 순위가 급한 일을 처리할 필요가 있을 때 대처할 수 있는 방안**

이 필요하다.

예를 들면, 키보드의 키를 하나 누르면, 눌려진 키 코드 값이 키보드 버퍼에 입력된 후 CPU에 인터럽트가 걸린다. 그럼 현재 처리하던 작업에 대한 정보를 수집하여 저장한 뒤에 인터럽트 서비스 루틴(Interrupt Service Routine)을 수행한다.(이 경우에는 키보드 버퍼에 있는 키 코드 값을 가져가는 일을 한다.) 이렇게 인터럽트 처리를 마친 후에는 다시 이전에 처리하던 작업으로 돌아간다.

### 인터럽트는 왜 필요한가?

선점형 스케줄러를 예로 들면 프로세스가 Running 중에 스케줄러에 의해 중단되게 됩니다. 이유는 다른 프로세스로 교체하기 위함이죠. 그렇게 하기 위해서는 스케줄러의 코드가 실행이되서 현재 진행중인 프로세스를 중지시킬 수 있어야 합니다. 스케줄러도 하나의 프로그램이니까요.

프로세스가 스스로 결정하는것은 진행 중에 I/O장치 혹은 다른 작업을 진행해야 해서 Block 상태가 되는것과 프로세스가 종료되서 Exit상태가 되는것이지 Running 상태에서는 스케줄러에의해 강제로 Ready상태가 되는겁니다. 프로세스가 스스로 중단하는것이 아니라 스케줄러가 강제로 중단을 시키는것이고 인터럽트는 이러한 부분에서도 필요한 기능입니다.

### 인터럽트의 종류에 대해 설명해 주세요.

- 외부 인터럽트: 입출력 장치, 타이밍 장치, 전원 등의 외부적인 요인에 의해서 발생하는 인터럽트.
    - 전원 이상 인터럽트: 정전이나 전원이 이상이 있는 경우
    - 기계 고장 인터럽트: CPU등의 기능적인 동작 오류가 발생한 경우
    - 입출력 인터럽트(I/O Interrupt): 입출력의 종료 등의 이유로 CPU의 수행을 요청하는 인터럽트.
- 내부 인터럽트: 잘못된 명령이나 데이터를 사용할 때 발생하는 인터럽트
    - 0으로 나누는 경우
    - 오버플로우 또는 언더플로우가 발생한 경우
    - 프로그램 상의 오류
    - 프로그램에서 함수 등 명령어를 잘못 사용한 경우
    - 소프트웨어 인터럽트: CPU가 인스트럭션을 수행하는 도중에 일어나는 인터럽트

> 내부 인터럽트 === 소프트웨어 인터럽트
외부 인터럽트 === 하드웨어 인터럽트
>

### 동기적 인터럽트

프로세스가 실행 중인 명령어로 인해 발생하는 인터럽트를 **동기적 인터럽트(내부 인터럽트)**라 한다.

- 프로그램상의 문제로 인해
- 작업자가 의도적으로
- 입출력장치 같은 주변장치의 조작에 의한
- 산술연산중 발생

### 비동기적 인터럽트

그리고 다른 하드웨어 장치가 실행 중인 명령어와 무관하게 생성하는 인터럽트를 **비동기적 인터럽트(외부 인터럽트)**라 한다.

- 하드디스크 읽기 오류
- 메모리 불량과 같은 하드웨어적인 오류
- 사용자가 직접 작동하는 키보드 인터럽트, 마우스 인터럽트

+) 보통 동기적인 인터럽트를 예외(Exception), 비동기적인 인터럽트를 인터럽트라고 한다,

### 인터럽트 처리 과정에 대해 설명해 주세요.

1. **인터럽트 요청**
2. **프로그램 실행 중단:** 현재 실행중이던 Micro operation 까지 수행
3. **현재의 프로그램 상태 보존:** PCB(Process Control Block), PC(Program Counter) 등
4. **인터럽트 원인 판별:**
    - 인터럽트를 요청한 장치를 식별
    - Interrupt Vector 테이블을 참조하여 호출할 ISR 주소 값을 얻는다.
5. **ISR(Interrupt Service Routine) 실행**
    - 인터럽트 발생시 실행할 함수
    - 실질적인 인터럽트 처리 작업 수행
    - 서비스루틴 수행 중 우선순위가 더 높은 인터럽트가 발생하면 또 재귀적으로 1~5를 수행한다.
    - 인터럽트 서비스 루틴을 실행할 때 인터럽트 플래그(IF)를 0으로 하면 인터럽트 발생을 방지할 수 있다.
6. **상태복구 :** 인터럽트 발생 시 저장해둔 PC(Program counter)를 다시 복구하여 이전 실행 위치로 돌아간다.
7. **중단된 프로그램 실행 재개:** PCB의 값을 이용하여 이전에 수행중이던 프로그램을 재개한다.

### 이중 동작 모드에 대해 설명해 주시고, 처리과정에 대해 말씀해 주세요.

이중 동작 모드란 다중 프로그래밍 환경에서 운영체제를 보호하는 보안 기법이다. 응용 프로그램이 운영체제의 자원(메모리, CPU, 하드디스크 등)에 직접 접근하는 것을 방지하기 위해 유저 모드(User mode), 커널 모드(Kernel mode) 두 가지 모드로 분리되어있다. CPU는 두 가지 모드에서 명령어를 실행할 수 있는데 요청에 따라 모드를 전환한다.

### 이중동작모드 과정

1. 실행중인 프로그램(유저모드)
2. 인터럽트 발생 후 CPU로 인터럽트 신호 요청(유저모드)
3. CPU에서 모드 플래그를 0으로 변경(커널모드)
4. 해당 하드웨어 인터럽트 서비스 루틴으로 이동(커널모드)
5. 인터럽트 처리(커널모드)
6. 인터럽트 처리 후 CPU의 모드 플래그를 1로 변경(유저모드)
7. 원래의 애플리케이션 위치로 복귀(유저모드)

### 이중 동작 모드가 필요한 이유는 무엇인가요?

- 잘못된 사용자로부터 운영체제를 보호, 잘못된 사용자 서로를 보호하는 방법을 제공해준다.
- 운영체제 내부에는 **나쁜 영향을 끼칠 수 있는 일부 명령들을 특권명령(privileged instruction)으로 지정**함으로써 **운영체제 자신과 사용자에게 시스템적 보호를 제공**한다.
    - 유저모드에서 불법적인 명령을 실행하지 못하게 해놓음.
    - 이에따라, **하드웨어는 특권명령이 커널모드에만 실행되도록 허용**한다.
    - 유저모드에서 특권명령을 실행하려고 시도하면, 하드웨어는 이를 실행하지 않고, 불법적인 명령으로 간주해 운영체제로 트랩을 건다.
- 커널 모드로 전환하는 명령어가 특권 명령의 한 예이다. 또 다른 예는 입출력 제어, 타이머 관리, 그리고 인터럽트 관리를 위한 명령어들이 있다.
- 불법적인 명령이 이중 동작 모드가 필요한 유일한 이유는 아니다.
    - 만약, 이중 동작 모드가 없다면, 잘못된 사용자 프로그램이 데이터를 운영체제 부분에 덮어 기록함으로써 운영체제를 지워버릴 수 있고, 또한 여러 프로그램이 동시에 한 장치에 기록할 수 있으며, 그 경우 예상치 못한 결과가 발생할 수 있다.
