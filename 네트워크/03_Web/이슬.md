# 📍 키워드
- Web
    - Web Server vs WAS
        - https://github.com/WeareSoft/tech-interview/blob/master/contents/etc.md#web-server%EC%99%80-was%EC%9D%98-%EC%B0%A8%EC%9D%B4
        - https://github.com/bombo-dev/CS-JAVA-Study/blob/main/Network/%EC%9B%B9%EC%84%9C%EB%B2%84%2C%20WAS.md
        - https://gmlwjd9405.github.io/2018/10/27/webserver-vs-was.html
    - Web Server
        - 사용 이유
        - apache vs nginx (동작원리)
            - https://velog.io/@deannn/Apache%EC%99%80-NginX-%EB%B9%84%EA%B5%90-%EC%B0%A8%EC%9D%B4%EC%A0%90
            - https://sorjfkrh5078.tistory.com/289
            - https://www.nexcess.net/blog/nginx-vs-apache/
            - https://ssdragon.tistory.com/60
            - https://rootkey.tistory.com/143
        - SSL offloading
            - https://minholee93.tistory.com/entry/SSL-offloading-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C
        - reverse proxy, forward proxy
            - https://inpa.tistory.com/entry/NETWORK-%F0%9F%93%A1-Reverse-Proxy-Forward-Proxy-%EC%A0%95%EC%9D%98-%EC%B0%A8%EC%9D%B4-%EC%A0%95%EB%A6%AC
        - load balancing
            - https://github.com/gyoogle/tech-interview-for-developer/blob/master/Computer%20Science/Network/%EB%A1%9C%EB%93%9C%20%EB%B0%B8%EB%9F%B0%EC%8B%B1(Load%20Balancing).md
            - https://aws.amazon.com/ko/what-is/load-balancing/
            - https://m.post.naver.com/viewer/postView.naver?volumeNo=27046347&memberNo=2521903
            - https://www.smileshark.kr/post/what-is-a-load-balancer-a-comprehensive-guide-to-aws-load-balancer
            - L7 vs L4
                - https://dodghek.tistory.com/33
            - 알고리즘
    - Cache
        - https://hahahoho5915.tistory.com/33
        - https://hi-guten-tag.tistory.com/376
    - URI, URN, URL
        - https://inpa.tistory.com/entry/WEB-%F0%9F%8C%90-URL-URI-%EC%B0%A8%EC%9D%B4
    - Rest API
        - https://github.com/WeareSoft/tech-interview/blob/master/contents/network.md#rest%EC%99%80-restful%EC%9D%98-%EA%B0%9C%EB%85%90

<br>

# 📍 예상 질문
## Web Server vs WAS
- 웹서버와 WAS의 차이점이 무엇인지 설명해주세요.
    - 웹 서버는 정적인 파일(예: HTML, CSS, 이미지)을 제공하는 역할을 합니다. 대표적으로 아파치(Apache)와 엔진엑스(Nginx)가 있습니다. 이들 웹 서버는 클라이언트의 요청을 받아들이고, 그에 맞는 정적 파일을 응답으로 제공합니다. 웹 서버는 주로 웹 페이지의 전달과 같은 단순한 기능을 수행하는 역할을 담당합니다.
    - 한편, WAS 서버는 동적인 콘텐츠를 생성하고, 데이터를 처리하는 역할을 합니다. WAS는 웹 애플리케이션을 실행하기 위한 서버로, 사용자의 요청에 따라 데이터베이스 조회, 비즈니스 로직 처리 등 다양한 작업을 수행합니다. 웹 애플리케이션의 실행 환경을 제공하며, 다른 서버와의 통신을 통해 필요한 데이터를 가져와 동적인 응답을 생성합니다.
    - 이처럼, 웹 서버와 WAS 서버는 각각 다른 역할과 기능을 가지고 있습니다. 웹 서버는 정적인 파일 제공에 특화되어 있고, WAS 서버는 동적인 콘텐츠 생성과 데이터 처리에 특화되어 있습니다. 때문에, 웹 애플리케이션을 구성할 때는 웹 서버와 WAS 서버를 함께 사용하여 역할을 분담하고 최적의 성능을 내도록 하는 것이 일반적입니다.
- Web Server와 WAS를 구분하는 이유는 무엇일까요?
    - WAS는 웹 서버가 수행하는 기능을 같이 제공해 줄 수 있습니다. 그럼에도 불구하고 웹 서버가 필요한 이유는 WAS가 처리하는 일 중에서 비즈니스 로직을 수행하는 부분은 상당히 많은 비용을 소모하게 됩니다. (DB 트랜잭션, 스레드, 예외 등)
    - 위의 비즈니스 로직을 수행하던 도중 큰 문제가 발생하여 WAS가 다운 될 경우, 웹 사이트에 오류가 발생했다는 정적 페이지도 뿌리지 못하고 접속 장애가 발생하는 상황이 발생합니다.
    - 정적 페이지를 호출하는 부분은 웹 서버에게 일임하고, 동적인 부분을 처리하는 부분을 WAS에 일임하여 각 서버들끼리에 부하를 줄이고, WAS 문제 발생 시 웹 서버가 오류 페이지를 띄울 수 있도록 할 수 있습니다.
    - 추가적으로, 웹 서버와 WAS를 분리하게 되면 웹 서버와 WAS간의 유연한 확장 또한 가능합니다. 웹 서버의 자원이 부족하면 웹 서버를 증설하고, WAS의 자원이 부족하면 WAS를 증설하는 것입니다.
    - https://gmlwjd9405.github.io/2018/10/27/webserver-vs-was.html

- 스프링 부트에서 제공해주는 WAS는 무엇일까요?
    - 기본적으로 Spring Boot에는 아파치 톰캣이 내장되어있어 사용자가 서버로 요청을 보내게되면, 특정 포트로 오는 요청을 잡아 SpringBoot 어플리케이션으로 연결시켜주는 것 입니다.

## apache vs nginx
- Apache와 NGINX는 각각 어떻게 작동하나요?
    - Apache
        - 요청 처리: Apache는 클라이언트로부터의 요청을 받으면, 해당 요청을 처리하기 위해 프로세스 또는 쓰레드를 생성합니다. 각각의 요청은 독립적으로 처리되며, 요청을 처리하는 동안에는 해당 프로세스 또는 쓰레드가 점유됩니다.
        - 멀티 프로세스/쓰레드: Apache는 기본적으로 멀티 프로세스 또는 멀티 쓰레드 방식으로 동작합니다. 이는 동시에 여러 요청을 처리할 수 있도록 하며, 각각의 프로세스 또는 쓰레드는 독립적으로 요청을 처리합니다.
        - 모듈 아키텍처: Apache는 모듈 기반 아키텍처를 가지고 있어 다양한 모듈을 추가하거나 확장할 수 있습니다. 이를 통해 웹 서버의 기능을 확장하거나 사용자 정의 모듈을 개발할 수 있습니다.
    - NGINX
        - 이벤트 기반 아키텍처: NGINX는 이벤트 기반 비동기 아키텍처를 기반으로 동작합니다. 이벤트 기반 방식은 비동기적으로 요청을 처리하며, 단일 쓰레드 또는 몇 개의 쓰레드만 사용하여 많은 수의 동시 연결을 처리할 수 있습니다.
        - 비동기 I/O: NGINX는 비동기 I/O 모델을 사용하여 입력/출력 작업을 효율적으로 처리합니다. 이는 동시에 많은 연결을 처리하면서도 적은 시스템 리소스를 사용할 수 있도록 합니다.
        - 리버스 프록시 및 로드 밸런싱: NGINX는 강력한 리버스 프록시 및 로드 밸런싱 기능을 제공합니다. 이를 통해 여러 대의 서버에 트래픽을 분산하거나, 웹 서버 뒤의 애플리케이션 서버와 연결할 수 있습니다.

- Apache와 NGINX 두 서버의 차이점은 무엇인가요?
    - 아키텍처
        - Apache: Apache는 멀티 프로세스/쓰레드 아키텍처를 사용합니다. 각 클라이언트 요청마다 새로운 프로세스 또는 쓰레드를 생성하여 처리합니다. 이는 메모리 사용량이 높을 수 있고, 동시에 많은 요청을 처리할 때 성능에 영향을 줄 수 있습니다.
        - NGINX: NGINX는 이벤트 기반 비동기 아키텍처를 가지고 있습니다. 단일 쓰레드 또는 몇 개의 쓰레드로 요청을 비동기적으로 처리합니다. 따라서 적은 리소스로 많은 동시 연결을 처리할 수 있고, 높은 성능을 제공합니다.
    - 성능
        - Apache: Apache는 정적인 콘텐츠에 대해서는 좋은 성능을 보이지만, 동적인 콘텐츠 처리에는 상대적으로 느릴 수 있습니다.
        - NGINX: NGINX는 정적인 콘텐츠와 동적인 콘텐츠 모두에 대해 빠른 성능을 제공합니다. 비동기적인 처리 방식과 효율적인 I/O 관리로 인해 높은 처리량과 낮은 지연 시간을 보여줍니다.
    - 메모리 사용량
        - Apache: Apache는 각각의 요청마다 프로세스 또는 쓰레드를 생성하므로, 많은 동시 연결이 발생할 경우 메모리 사용량이 높아질 수 있습니다.
        - NGINX: NGINX는 이벤트 기반 아키텍처로 동작하며, 적은 수의 쓰레드로 많은 연결을 처리할 수 있습니다. 따라서 메모리 사용량이 상대적으로 적습니다.
    - 리버스 프록시 및 로드 밸런싱
        - Apache: Apache는 리버스 프록시와 로드 밸런싱을 지원하지만, NGINX보다 구성이 복잡할 수 있습니다.
        - NGINX: NGINX는 리버스 프록시와 로드 밸런싱 기능을 내장하고 있어 간편하게 설정할 수 있습니다. 효율적인 로드 밸런싱을 통해 여러 대의 서버에 트래픽을 분산시킬 수 있습니다.

- 어떠한 상황애서 Apache를 쓰고 어떠한 상황에서 Nginx를 쓰는게 좋을까요?
    - Apache를 사용하는 상황
        - 동적 콘텐츠 처리: Apache는 PHP, Perl, Python과 같은 스크립트 언어를 처리하는 데 강점을 가지고 있습니다. 따라서 동적인 웹 애플리케이션을 개발하고자 할 때 Apache를 사용하는 것이 적합합니다.
        - 모듈 확장성: Apache는 모듈 기반 아키텍처를 가지고 있어 다양한 모듈을 추가하거나 확장하여 웹 서버의 기능을 확장할 수 있습니다. 특정한 기능이나 요구사항을 충족시키기 위해 사용자 정의 모듈을 개발할 수도 있습니다.
        - 호스팅 환경: Apache는 다중 도메인 호스팅, 가상 호스팅과 같은 환경에서 널리 사용됩니다. .htaccess 파일을 사용하여 디렉토리별로 웹 서버의 동작을 세밀하게 제어할 수 있는 기능을 제공하기 때문에 호스팅 환경에서 유연하게 사용할 수 있습니다.
    - NGINX를 사용하는 상황
        - 정적 파일 서비스: NGINX는 정적 파일 서비스에 특화되어 있습니다. 정적 파일을 빠르게 처리하고 서비스할 수 있는 성능을 가지고 있으므로, 정적 콘텐츠 제공이 주요 목표인 경우에 적합합니다.
        - 고성능 요구사항: NGINX는 이벤트 기반 비동기 아키텍처를 기반으로 동작하며, 많은 수의 동시 연결을 처리할 수 있는 능력을 가지고 있습니다. 따라서 고성능이 요구되는 상황에서 NGINX를 사용하는 것이 적합합니다.
        - 로드 밸런싱과 리버스 프록시: NGINX는 로드 밸런싱과 리버스 프록시 기능을 강력하게 지원합니다. 여러 대의 서버에 트래픽을 분산하거나, 웹 서버 뒤의 애플리케이션 서버와 연결하는 용도로 사용될 때 NGINX가 적합합니다.

- 웹 서버 소프트웨어(Apache, Nginx)의 서버 간 라우팅 기능은 OSI 7계층 중 어디서 작동하는지 설명해보세요.
    - 두 가지가 있습니다. Layer 4 (Transport Layer), 그리고 Layer 7 (Application Layer) 입니다. L4 에서는 TCP/UDP 포트 정보를 토대로 라우팅 기능이 제공됩니다. L7에서는 TCP/UDP 뿐만 아니라 HTTP의 URI 등을 토대로 라우팅 기능이 제공 됩니다. L4 에서 라우팅 기능을 사용 한 예시를 들자면, Nginx 의 경우 여러 포트들을 하나의 upstream 블록으로 묶어서 로드 밸런싱, 즉 특정 경로로 전달되는 요청을 각 포트 별로 분산해서 전달하도록 설정 해 줄 수 있습니다. L7 에서 라우팅 기능을 사용 한 예시를 들자면, Apache, Nginx 각각에서 서브 도메인에 대해 라우팅 설정을 해 둘 수 있습니다. 브라우저에서 /test 와 같은 서브 도메인으로 HTTP 프로토콜을 통한 요청을 보낸다면, 웹서버 내 Config 파일에 설정 된 경로 정보를 토대로 요청에 대한 라우팅을 제공하여 스태틱 파일을 전달하거나 API 서버에 대해 리버스 프록시 역할을 해 줄 수 있습니다.
    - 웹 서버 소프트웨어인 Apache와 NGINX의 서버 간 라우팅 기능은 OSI 7계층 중 4계층인 전송 계층에서 작동합니다. 라우팅은 네트워크 트래픽을 목적지로 전달하기 위해 경로를 선택하는 과정을 말합니다. 웹 서버 소프트웨어는 클라이언트로부터의 요청을 받아 해당 요청을 처리하기 위해 적절한 서버로 전달해야 합니다. 이때 서버 간 라우팅 기능을 사용하여 요청을 올바른 서버로 전송합니다. 라우팅은 전송 계층에서 작동하는데, 이는 TCP(Transmission Control Protocol)와 UDP(User Datagram Protocol)와 같은 전송 계층 프로토콜을 사용하기 때문입니다. 웹 서버 소프트웨어는 클라이언트로부터의 요청을 받을 때, 전송 계층에서 해당 요청을 받아와서 요청의 목적지 주소를 확인하고, 그에 따라 적절한 서버로 요청을 전달합니다. 따라서 Apache와 NGINX의 서버 간 라우팅 기능은 OSI 7계층 중 4계층인 전송 계층에서 작동하여 웹 서버의 효율적인 트래픽 분배와 요청 처리를 담당합니다.

## SSL offloading
- SSL Offloading은 무엇인가요?
    - SSL Offloading은 SSL (Secure Sockets Layer) 또는 TLS (Transport Layer Security) 암호화 및 복호화 작업을 웹 서버 외부에서 처리하는 것을 말합니다.
    - 일반적으로 웹 서버는 HTTPS 프로토콜을 사용하여 클라이언트와의 통신을 암호화합니다. 이때 SSL/TLS 인증서를 사용하여 암호화된 연결을 설정하고 유지합니다. 그러나 SSL/TLS 암호화는 CPU 리소스를 많이 사용하므로 웹 서버에 부하를 줄 수 있습니다.
    - SSL Offloading은 이러한 부하를 외부 리소스로 분산시키는 기술입니다. 일반적으로 로드 밸런서나 SSL 가속 장치가 웹 서버 앞에 배치되어 SSL/TLS 연결을 처리합니다. 이 장치들은 클라이언트와의 SSL/TLS 핸드셰이크를 처리하고, 암호화 및 복호화 작업을 담당합니다. 그리고 암호화되지 않은 데이터를 웹 서버로 전달합니다.
    - 이로써 웹 서버는 암호화 작업에 필요한 리소스를 절약할 수 있으며, 더 많은 클라이언트 요청을 처리할 수 있게 됩니다. 또한 SSL Offloading은 웹 서버의 성능을 향상시키고, SSL/TLS 인증서 관리를 단순화할 수 있는 장점을 제공합니다.
    - 이러한 SSL Offloading은 대규모 웹 사이트나 부하가 많은 애플리케이션에서 특히 유용합니다. 그러나 보안 측면에서는 로드 밸런서나 SSL 가속 장치가 웹 서버 앞에서 SSL/TLS 연결을 처리하므로, 이 장치들의 보안 설정과 관리가 중요합니다.

- SSL Offloading을 사용하는 이유는 무엇인가요?
    - 성능 향상: SSL/TLS 암호화 작업은 CPU 리소스를 많이 사용합니다. 웹 서버가 SSL/TLS 연결을 처리하면서 암호화와 복호화 작업을 수행하면 성능 저하가 발생할 수 있습니다. SSL Offloading을 사용하면 암호화 작업을 전담 장치(로드 밸런서, SSL 가속 장치 등)로 오프로드하여 웹 서버의 부하를 줄이고 성능을 향상시킬 수 있습니다.
    - 확장성: SSL Offloading을 사용하면 웹 서버가 더 많은 클라이언트 요청을 처리할 수 있습니다. 암호화 작업을 전담 장치로 분산시킴으로써 웹 서버의 리소스를 확보하고, 대량의 동시 연결에 대응할 수 있습니다.
    - 유연성: SSL Offloading을 통해 웹 서버와 SSL/TLS 연결 처리 장치를 분리함으로써, 각각을 독립적으로 업그레이드하거나 교체할 수 있습니다. 웹 서버와 SSL/TLS 연결 처리 장치 간의 유연한 구성 변경이 가능하므로 시스템 유지 관리가 용이해집니다.
     - 인증서 관리 간소화: SSL Offloading을 사용하면 웹 서버가 SSL/TLS 인증서를 관리할 필요가 없습니다. 인증서는 전담 장치에서 관리되며, 웹 서버는 암호화되지 않은 데이터만 처리하면 되므로 인증서 관리가 단순화됩니다.
    - 보안 강화: SSL Offloading을 사용하는 경우, 로드 밸런서나 SSL 가속 장치와 같은 전담 장치는 SSL/TLS 연결을 처리하고 보안 기능을 제공합니다. 이를 통해 보안 설정을 중앙 집중화하고, 보안 강화를 위한 추가적인 기능을 활용할 수 있습니다.

## reverse proxy, forward proxy
- Proxy 서버에 대해서 간략하게 설명해주세요.
    - 프록시 서버는 클라이언트와 원격 서버 사이에서 중개자 역할을 수행하는 서버입니다. 클라이언트는 프록시 서버를 통해 인터넷에 접근하고, 프록시 서버는 클라이언트의 요청을 받아서 대신 원격 서버에 요청을 전달하고 응답을 클라이언트에게 전달합니다.

- Forward Proxy와 Reverse Proxy의 차이점에 대해 설명해주세요.
    - 프록시 서버 위치
        - Forward Proxy 서버는 클라이언트와 원격 서버 사이에서 동작하며, 클라이언트의 요청을 대신 전달합니다. 
        - Reverse Proxy 서버는 웹 서버 뒷단에서 동작하며, 클라이언트의 요청을 적절한 서버로 전달합니다.
    - 감춰지는 대상
        - Forward Proxy는 직접 서버 url로 요청을 보내지만, Reverse Proxy는 프록시 서버 url로만 접근이 가능합니다. 이로서 Reverse Proxy는 본서버의 IP 정보를 숨길수 있는 효과를 얻게 됩니다.
        - Forward Proxy는 내부망에서 인터넷 상에 있는 서버에 요청할때 먼저 포워드 프록시 서버를 호출하고 프록시가 서버에게 요청을 보내게 되는데, 이로서 서버에게 클라이언트가 누구인지 감출수 있습니다. 즉, 서버 입장에서 응답받은 IP는 포워드 Forward Proxy의 IP이기 때문에 클라이언트가 누군지 알 수 없습니다.
    - 사용 목적
       - Forward Proxy는 주로 보안, 익명성, 캐싱 등의 목적으로 사용됩니다.
       - Reverse Proxy는 주로 로드 밸런싱, 보안, SSL 암호화, 애플리케이션 계층 방화벽 등의 목적으로 사용됩니다.

## 로드 밸런서
- 서버에 많은 트래픽이 발생했을 때 대처 할 수 있는 방안에 대해서 설명해주세요.
    - 스케일 업 및 스케일 아웃으로 대처할 수 있습니다.
    - 스케일 업은 서버의 성능을 향상시키기 위해 서버의 하드웨어 리소스를 강화하는 것을 의미합니다. 예를 들어, CPU, 메모리, 디스크 용량 등을 업그레이드하여 서버의 성능을 향상시킬 수 있습니다. 
    - 스케일 아웃은 서버의 대수를 늘려서 처리 능력을 확장하는 것을 의미합니다. 여러 대의 서버를 추가하여 트래픽을 분산시키고, 병렬 처리를 통해 성능을 향상시킬 수 있습니다. 단, 스케일 아웃을 하게 되면 서버가 여러 대가 되기 때문에 각 서버에 걸리는 부하를 고르게 나누기 위해서는 로드밸런싱이 필수적으로 동반되어야 합니다.

- L4 로드밸런서와, L7 로드밸런서의 차이에 대해 설명해 주세요.
    - L4 로드 밸런서
        - L4 로드 밸런서는 전송 계층에서 동작합니다. IP 주소와 포트 번호를 기반으로 트래픽을 분산시키는 기능을 제공합니다. L4 로드 밸런서는 TCP, UDP와 같은 전송 계층 프로토콜을 분석하여 트래픽을 로드 밸런싱할 수 있습니다. 이는 서버의 성능과 가용성을 향상시키는 데 도움이 됩니다. L4 로드 밸런서는 네트워크 계층에서 동작하므로, 패킷 기반으로 동작하며, 보다 빠른 속도와 낮은 대기 시간을 제공할 수 있습니다.
    - L7 로드 밸런서
        - L7 로드 밸런서는 응용 계층에서 동작합니다. L7 로드 밸런서는 L4 로드 밸런서의 기능을 포함하면서, HTTP 헤더, URL, 쿠키와 같은 응용 계층 데이터를 분석하여 트래픽을 분산시킵니다. 이로써 요청의 종류나 내용에 따라 트래픽을 더 세밀하게 제어할 수 있습니다. 예를 들어, 특정 URL 패턴에 대해 특정 서버로 트래픽을 라우팅하거나, SSL 오프로딩과 같은 고급 기능을 제공할 수 있습니다. L7 로드 밸런서는 애플리케이션 계층에서 동작하므로, 애플리케이션의 상태를 파악하고 트래픽을 조작할 수 있는 장점이 있습니다.
    - 요약하자면, L4 로드 밸런서는 IP 주소와 포트 번호를 기반으로 트래픽을 분산시키는 반면, L7 로드 밸런서는 응용 계층의 데이터를 분석하여 트래픽을 조작할 수 있습니다. L7 로드 밸런서는 더 세밀한 제어와 기능을 제공하지만, 처리 시간이 더 오래 걸릴 수 있습니다. 따라서, 선택은 사용하고자 하는 기능과 요구 사항에 따라 달라집니다.

- 로드밸런서 알고리즘에 대해 설명해 주세요.
    - 라운드로빈 방식(Round Robin Method)은 서버에 들어온 요청을 순서대로 돌아가며 배정하는 방식입니다. 클라이언트의 요청을 순서대로 분배하기 때문에 여러 대의 서버가 동일한 스펙을 갖고 있고, 서버와의 연결이 오래 지속되지 않는 경우에 적합합니다.
    - 가중 라운드로빈 방식(Weighted Round Robin Method)은 각각의 서버마다 가중치를 매기고 가중치가 높은 서버에 클라이언트 요청을 우선적으로 배분합니다. 주로 서버의 트래픽 처리 능력이 상이한 경우에 사용되는 부하 분산 방식입니다.
    - IP 해시 방식(IP Hash Method)은 클라이언트의 IP 주소를 특정 서버로 매핑하여 요청을 처리하는 방식입니다. 사용자의 IP를 해싱해 로드를 분배하기 떄문에 사용자가 되도록 동일한 서버로 연결되는 것을 보장합니다.
    - 최소 연결 방식(Least Connection Method)은 요청이 들어온 시점에 가장 적은 연결상태를 보이는 서버에 우선적으로 트래픽을 배분합니다. 세션이 길어지거나 서버에 분배된 트래픽들이 일정하지 않은 경우에 적합합니다.
    - 최소 응답 시간 방식(Least Response Time Method)은 서버의 현재 연결 상태와 응답시간을 모두 고려하여 트래픽을 배분합니다. 가장 적은 연결 상태와 가장 짧은 응답 시간을 보이는 서버에 우선적으로 배분하는 방식입니다.

- 로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능하다고 가정해 봅시다. 이 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하려면 어떻게 해야 할까요?
    - 헬스 체크 설정: 로드 밸런서는 헬스 체크라는 기능을 제공합니다. 이를 사용하여 로드 밸런서가 대상 장치의 상태를 주기적으로 확인할 수 있습니다. 대상 장치가 응답하지 않거나 정상적인 상태가 아닐 경우, 로드 밸런서는 해당 장치로 요청을 보내지 않습니다.
    - 서비스 업데이트: 장애가 발생한 대상 장치를 로드 밸런서의 대상에서 제거하는 것입니다. 장치를 수리하거나 대체할 때까지 해당 장치를 로드 밸런서에서 제외합니다. 이를 통해 로드 밸런서는 오직 정상적으로 작동하는 장치로만 트래픽을 전달합니다.
    - 가중치 조정: 로드 밸런서는 대상 장치에 대한 가중치를 설정할 수 있습니다. 장애가 발생한 장치의 가중치를 0으로 설정하면 해당 장치로의 트래픽이 전달되지 않습니다. 다른 정상적인 장치의 가중치를 높여서 트래픽을 분산시킬 수 있습니다.

## Cache
- Web Cache는 무엇인가요?
    - Web Cache(웹 캐시)는 웹 페이지나 웹 리소스의 사본을 저장하고, 이를 향후 요청에 사용하는 임시 저장소입니다. 
    - 일반적으로 웹 브라우저나 프록시 서버에 웹 캐시가 구현됩니다. 사용자가 웹 페이지에 접속하면, 웹 캐시는 해당 페이지의 사본을 가져와서 사용자에게 제공합니다. 이후 사용자가 동일한 페이지에 재접속하거나 다른 사용자가 동일한 페이지에 접속하면, 웹 캐시는 이미 저장된 사본을 사용하여 웹 서버에 요청을 보내지 않고도 페이지를 제공할 수 있습니다.

- Web Cache를 사용해서 얻는 이점은 무엇인가요?
    - 로딩 속도 향상: 웹 캐시는 웹 페이지의 사본을 저장하여 사용자에게 빠른 로딩 속도를 제공합니다. 웹 페이지의 사본이 이미 로컬에 저장되어 있기 때문에, 웹 서버로부터 데이터를 다운로드하는 시간이 단축됩니다. 사용자는 빠르게 웹 페이지를 로드할 수 있어서 사용자 경험을 향상시킵니다.
    - 대역폭 절약: 웹 캐시는 웹 페이지의 사본을 저장하고 제공함으로써 네트워크 대역폭을 절약할 수 있습니다. 사용자가 웹 페이지에 접속할 때 웹 서버로부터 데이터를 다운로드하는 대신, 웹 캐시로부터 데이터를 가져올 수 있습니다. 이는 웹 서버의 부하를 줄이고 네트워크 트래픽을 최적화하는 데 도움이 됩니다.
    - 서버 부하 감소: 웹 캐시는 웹 서버의 부하를 줄여줍니다. 웹 캐시가 웹 페이지의 사본을 제공하므로 웹 서버는 동일한 페이지에 대한 요청을 처리하는 횟수를 줄일 수 있습니다. 이는 웹 서버의 성능을 향상시키고 서버 리소스를 효율적으로 활용하는 데 도움이 됩니다.
    - 네트워크 지연 감소: 웹 캐시는 사용자와 웹 서버 사이의 네트워크 지연을 감소시킵니다. 웹 캐시는 사용자에게 가까운 위치에 배치될 수 있으며, 웹 페이지의 사본을 로컬에서 제공함으로써 네트워크 지연을 최소화합니다.

- Web Cache의 종류에 대해서 얘기해주세요.
    - 1. Browser Cache
        - 브라우저 캐시는 웹 브라우저에 내장된 캐시입니다. 브라우저는 사용자가 방문한 웹 페이지의 일부 또는 전체를 로컬 저장소에 저장하여 이후에 해당 페이지를 다시 방문할 때 빠르게 로딩할 수 있습니다.
        - Cache된 Resource를 공유하지 않는 한 개인에 한정된 Cache 입니다.
        - 브라우저의 Back버튼 또는 이미 방문한 페이지를 재 방문하는 경우 캐시의 이점이 극대화 됩니다.
    2. Proxy Cache
        - 프록시 서버는 클라이언트와 웹 서버 사이에서 중개 역할을 하는 서버입니다.. 프록시 캐시는 웹 페이지의 사본을 저장하고 클라이언트에게 제공함으로써 웹 서버의 부하를 줄이고 로딩 속도를 향상시킵니다. 프록시 서버는 여러 클라이언트를 대상으로 한 번 다운로드한 웹 페이지를 여러 번 제공할 수 있습니다.
    3. Gateway Cache
        - 게이트웨이 캐시는 웹 서버와 인터넷 사이에 위치한 캐시입니다. 게이트웨이 캐시는 다수의 클라이언트 요청에 대해 중복되는 데이터를 저장하여 웹 서버의 부하를 줄이고 로딩 속도를 향상시킵니다. 게이트웨이 캐시는 웹 서버의 앞단에서 동작하며, 네트워크 대역폭과 서버 리소스 사용을 최적화하는 데 도움이 됩니다.
    4. CDN Cache
        - CDN 캐시는 컨텐츠 전송 네트워크(Content Delivery Network)에서 사용되는 캐시입니다. CDN은 전 세계에 분산된 서버 네트워크를 통해 웹 콘텐츠를 제공하며, CDN 캐시는 이 네트워크의 서버에 웹 페이지의 사본을 저장하여 사용자에게 빠르게 제공합니다. CDN 캐시는 지리적으로 가까운 위치에서 콘텐츠를 제공함으로써 로딩 속도를 향상시키고 대역폭을 절약합니다.

## URI, URN, URL
- URI와 URL, URN의 차이는 무엇인가요?
    - URI(Uniform Resource Identifier)는 인터넷 상의 리소스를 고유하게 식별하는 일반적인 개념입니다. URI는 URL과 URN을 모두 포함하는 상위 개념입니다. 즉, URI는 리소스의 식별자로서 어떤 형태의 표현 방식을 사용하던지 상관없이 리소스를 식별하는 데 사용됩니다.
    - URL(Uniform Resource Locator)은 가장 많이 사용되는 URI의 형태입니다. URL은 특정 리소스의 위치를 나타내며, 해당 리소스에 접근하는 방법을 정의합니다. URL은 프로토콜(예: HTTP, FTP), 호스트(예: www.example.com), 리소스의 경로 및 파일명 등을 포함합니다. 예를 들어, "https://www.example.com/index.html"은 URL의 예입니다.
    - URN(Uniform Resource Name)은 리소스의 이름을 나타냅니다. URN은 리소스의 위치에 상관없이 유일한 이름을 제공하여 리소스를 식별합니다. URN은 일반적으로 리소스의 내용, 속성 또는 기타 특성에 기반하여 생성됩니다. 예를 들어, "urn:isbn:0-486-27557-4"은 URN의 예로서 책의 ISBN 번호를 사용하여 책을 식별합니다.
    = 요약하자면, URI는 인터넷 상의 리소스를 식별하는 개념이며, URL은 리소스의 위치를 나타내는 방식 중 하나이며, URN은 리소스의 이름을 나타내는 방식 중 하나입니다. URL과 URN은 모두 URI의 특수한 형태로 볼 수 있습니다.

## Rest API
- REST API가 무엇인지 설명해주세요.
    - 먼저 REST에 대해 설명하자면, REST는 Representational State Transfer의 약자로, 웹 서비스를 개발하기 위한 아키텍처 스타일입니다. REST는 분산 시스템에서 클라이언트와 서버 간의 통신을 위한 규칙과 제약을 제공합니다. REST API는 REST 기반으로 서비스 API를 구현한 것입니다.

<br>

# 📍 Reference
- https://github.com/VSFe/Tech-Interview/blob/main/03-NETWORK.md
- https://github.com/dev-team-study/cs-study/tree/main/%5B1%ED%9A%8C%EC%B0%A8%5D2.network/09_WebServer
- https://github.com/ksundong/backend-interview-question